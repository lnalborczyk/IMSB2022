---
title: Introduction à la modélisation statistique bayésienne
subtitle: Un cours en R, Stan, et brms
author: Ladislas Nalborczyk (LPC, LNC, CNRS, Aix-Marseille Univ)
from: markdown+emoji
format:
  revealjs:
    incremental: true
    theme: [default, ../custom.scss]
    transition: none # fade
    background-transition: none # fade
    transition-speed: default # default, fast, or slow
    slide-number: c/t
    show-slide-number: all
    preview-links: true
    self-contained: true # when sharing slides
    # chalkboard: true
    csl: ../../files/bib/apa7.csl
    logo: ../../files/cover.png
    footer: "Ladislas Nalborczyk - IMSB2022"
    # width: 1200 # defaults to 1050
    # height: 900 # default to 700
    margin: 0.15 # defaults to 0.1
    scrollable: true
    hide-inactive-cursor: true
    pdf-separate-fragments: false
    highlight-style: zenburn
    code-copy: true
    code-link: false
    code-fold: false
    code-summary: "Voir le code"
    numbers: true
    progress: false
title-slide-attributes:
    data-background-color: "#1c5253"
bibliography: ../../files/bib/references.bib
editor_options: 
  chunk_output_type: console
---

## Planning

```{r setup, eval = TRUE, include = FALSE, cache = FALSE}
library(tidyverse)
library(patchwork)
library(brms)
library(imsb)

# setting up knitr options
knitr::opts_chunk$set(
  cache = TRUE, echo = TRUE,
  warning = FALSE, message = FALSE,
  fig.align = "center", dev = "svg"
  )

# setting up ggplot theme
theme_set(theme_bw(base_size = 16, base_family = "Open Sans") )
```

Cours n°01 : Introduction à l'inférence bayésienne <br> Cours n°02 :
Modèle Beta-Binomial <br> Cours n°03 : Introduction à brms, modèle de
régression linéaire <br> Cours n°04 : Modèle de régression linéaire
(suite) <br> Cours n°05 : Markov Chain Monte Carlo <br> **Cours n°06 :
Modèle linéaire généralisé** <br> Cours n°07 : Comparaison de modèles <br>
Cours n°08 : Modèles multi-niveaux <br> Cours n°09 : Modèles
multi-niveaux généralisés <br> Cours n°10 : Data Hackathon <br>

## Introduction

Le modèle linéaire Gaussien qu'on a vu aux Cours n°03 et n°04 est caractérisé par un ensemble de postulats, entre autres choses :

+ Les résidus sont distribués selon une loi Normale
+ La variance de cette distribution Normale est constante (postulat d'homogénéité de la variance)
+ Les prédicteurs agissent sur la moyenne de cette distribution
+ La moyenne suit un modèle linéaire ou multi-linéaire

. . .

<br>

$$
\begin{align}
y_{i} &\sim \mathrm{Normal}(\mu_{i}, \sigma)\\
\mu_{i} &= \alpha + \beta_{1} \cdot x_{1i} + \beta_{2} \cdot x_{2i}\\
\end{align}
$$

## Introduction

Cette modélisation (le choix d'une distribution Normale) induit plusieurs contraintes, par exemple :

+ Les données observées sont définies sur un espace continu
+ Cet espace n'est pas borné

. . .

Comment modéliser certaines données qui ne respectent pas ces contraintes ? Par exemple, la proportion de bonnes réponses à un test (bornée entre 0 et 1), un temps de réponse (restreint à des valeurs positives et souvent distribué de manière approximativement log-normale), un nombre d'accidents...

## Introduction

Nous avons déjà rencontré un modèle différent : le modèle Beta-Binomial (cf. Cours n°02).

+ Les données observées sont binaires (e.g., 0 vs. 1) ou le résultat d'une somme d'observations binaires (e.g., une proportion)
+ La probabilité de succès (obtenir 1) a priori se caractérise par une distribution Beta
+ La probabilité de succès (obtenir 1) ne dépend d'aucun prédicteur

. . .

<br>

$$
\begin{align}
w &\sim \mathrm{Binomial}(n, p) \\
p &\sim \mathrm{Beta}(a, b)
\end{align}
$$

## Introduction

Cette modélisation induit deux contraintes :

+ Les données observées sont définies sur un espace discret
+ Cet espace est borné

. . .

Comment pourrait-on ajouter des prédicteurs à ce modèle ?

## Modèle linéaire généralisé

$$
\begin{align}
y_{i} &\sim \mathrm{Binomial}(n, p_{i}) \\
f(p_{i}) &= \alpha + \beta \cdot x_{i} \\
\end{align}
$$

Objectifs :

+ Rendre compte de données discrètes générées par un processus unique
+ Introduire des prédicteurs dans le modèle

. . .

Deux changements par rapport au modèle Gaussien :

+ L'utilisation d'une distribution de probabilité Binomiale
+ Le modèle linéaire ne sert plus à décrire directement un des paramètres de la distribution, mais une fonction de ce paramètre (on peut aussi considérer que le modèle Gaussien était formulé avec une fonction identité)

## Fonction de lien

Les fonctions de lien  ont pour tâche de mettre en correspondance l'espace d'un modèle linéaire (non borné) avec l'espace d'un paramètre potentiellement borné comme une probabilité, définie sur l'intervalle $[0, 1]$.

```{r, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# plot from https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html#generalized-linear-models

tibble(x = seq(from = -1, to = 3, by = 0.01) ) %>%
  mutate(probability = 0.35 + x * 0.5) %>%
  ggplot(aes(x = x, y = probability) ) +
  geom_rect(xmin = -1, xmax = 3, ymin = 0,  ymax = 1, fill = "gray90") +
  geom_hline(yintercept = 0:1, linetype = 2) +
  geom_line(aes(linetype = probability > 1), size = 1) +
  geom_segment(x = 1.3, xend = 3, y = 1, yend = 1, size = 2 / 3) +
  scale_y_continuous(breaks = c(0, 0.5, 1) ) +
  coord_cartesian(xlim = c(0, 2), ylim = c(0, 1.2) ) +
  theme(legend.position = "none", panel.grid = element_blank() ) +
  labs(x = "Prédicteur", y = "Probabilité")
```

## Fonction de lien

Les fonctions de lien  ont pour tâche de mettre en correspondance l'espace d'un modèle linéaire (non borné) avec l'espace d'un paramètre potentiellement borné comme une probabilité, définie sur l'intervalle $[0, 1]$.

```{r, eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# plot from https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html#generalized-linear-models
# fonction logit utilisée dans le GLM binomial (ou régression logistique)

# make data for the horizontal lines
alpha <- 0
beta  <- 4

lines <-
  tibble(x = seq(from = -1, to = 1, by = 0.25) ) %>% 
  mutate(
    `log-odds` = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    )

# make the primary data 
beta <- 2

d <-
  tibble(x = seq(from = -1, to = 1, length.out = 50) ) %>% 
  mutate(
    `log-odds`  = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    ) 

# make the individual plots
p1 <-
  d %>% 
  ggplot(aes(x = x, y = `log-odds`) ) +
  geom_hline(
    data = lines,
    aes(yintercept = `log-odds`),
    color = "gray"
  ) +
  geom_line(size = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Prédicteur", y = "Log-odds")

p2 <-
  d %>% 
  ggplot(aes(x = x, y = probability) ) +
  geom_hline(
    data = lines,
    aes(yintercept = probability),
    color = "gray"
    ) +
  geom_line(size = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Prédicteur", y = "Probabilité")

p1 + p2

# finally, we're ready to mash the plots together and behold their nerdy glory
# (p1 | p2) +
#   plot_annotation(subtitle = "The logit link transforms a linear model (left) into a probability (right).")
# 
# 
# x <- seq.int(from = -1, to = 1, length.out = 1e2)
# y <- 0 + 2 * x
# 
# library(scales)
# 
# tn <- trans_new(
#   name = "logpeps",
#   transform = function(x) plogis(x),
#   inverse = function(y) log(y / (1 - y) ),
#   # inverse = function(y) y,
#   domain = c(0, Inf),
#   breaks = c(0, 0.1, 1)
#   )
# 
# data.frame(x = x, y = y) %>%
#   ggplot(aes(x = x, y = y) ) +
#   geom_line() +
#   theme_bw(base_size = 12) +
#   ylim(-4, 4) +
#   labs(y = "Log-odds")
# 
# data.frame(x = x, y = y) %>%
#   ggplot(aes(x = x, y = y) ) +
#   geom_line() +
#   coord_trans(y = tn) +
#   theme_bw(base_size = 12) +
#   ylim(0, 1) +
#   labs(y = "Probability")
```

## Régression logistique

La fonction logit du GLM binomial (on parle de "log-odds") :

$$\text{logit}(p_{i}) = \log \left(\frac{p_{i}}{1 - p_{i}} \right)$$

. . .

La cote d'un événement (*odds* en anglais) est le ratio entre la probabilité que l'événement se produise et la probabilité qu'il ne se produise pas. Le logarithme de cette cote est prédit par un modèle linéaire.

$$
\log \left(\frac{p_{i}}{1 - p_{i}} \right) = \alpha + \beta \cdot x_{i}
$$

. . .

Pour retrouver la probabilité d'un événement, il faut utiliser la fonction de **lien inverse**, la fonction **logistique** (ou logit-inverse) :

$$
p_{i} = \frac{\exp(\alpha + \beta \cdot x_{i})}{1 + \exp(\alpha + \beta \cdot x_{i})}
$$

## Complications induites par la fonction de lien

Ces fonctions de lien posent des problèmes d'interprétation : Un changement d'une unité sur un prédicteur n'a plus un effet constant sur la probabilité mais la modifie plus ou moins en fonction de son éloignement à l'origine. Quand $x = 0$, une augmentation d'une demi-unité (i.e., $x = 0.5$) se traduit par une augmentation de la probabilité de $0.25$. Puis, chaque augmentation d'une demi-unité se traduit par une augmentation de $p$ de plus en plus petite...

```{r, eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# plot from https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html#generalized-linear-models
# fonction logit utilisée dans le GLM binomial (ou régression logistique)

# make data for the horizontal lines
alpha <- 0
beta  <- 4

lines <-
  tibble(x = seq(from = -1, to = 1, by = 0.25) ) %>% 
  mutate(
    `log-odds` = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    )

# make the primary data 
beta <- 2

d <-
  tibble(x = seq(from = -1, to = 1, length.out = 50) ) %>% 
  mutate(
    `log-odds`  = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    ) 

# make the individual plots
p1 <-
  d %>% 
  ggplot(aes(x = x, y = `log-odds`) ) +
  geom_hline(
    data = lines,
    aes(yintercept = `log-odds`),
    color = "gray"
  ) +
  geom_line(size = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Prédicteur", y = "Log-odds")

p2 <-
  d %>% 
  ggplot(aes(x = x, y = probability) ) +
  geom_hline(
    data = lines,
    aes(yintercept = probability),
    color = "gray"
    ) +
  geom_line(size = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Prédicteur", y = "Probabilité")

p1 + p2

# finally, we're ready to mash the plots together and behold their nerdy glory
# (p1 | p2) +
#   plot_annotation(subtitle = "The logit link transforms a linear model (left) into a probability (right).")
# 
# 
# x <- seq.int(from = -1, to = 1, length.out = 1e2)
# y <- 0 + 2 * x
# 
# library(scales)
# 
# tn <- trans_new(
#   name = "logpeps",
#   transform = function(x) plogis(x),
#   inverse = function(y) log(y / (1 - y) ),
#   # inverse = function(y) y,
#   domain = c(0, Inf),
#   breaks = c(0, 0.1, 1)
#   )
# 
# data.frame(x = x, y = y) %>%
#   ggplot(aes(x = x, y = y) ) +
#   geom_line() +
#   theme_bw(base_size = 12) +
#   ylim(-4, 4) +
#   labs(y = "Log-odds")
# 
# data.frame(x = x, y = y) %>%
#   ggplot(aes(x = x, y = y) ) +
#   geom_line() +
#   coord_trans(y = tn) +
#   theme_bw(base_size = 12) +
#   ylim(0, 1) +
#   labs(y = "Probability")
```

## Complications induites par la fonction de lien

Deuxième complication : cette fonction de lien force chaque prédicteur à interagir avec lui même et à interagir avec TOUS les autres prédicteurs, même si les interactions ne sont pas explicites...

. . .

Dans un modèle Gaussien, le taux de changement de $y$ en fonction de $x$ est donné par $\partial(\alpha + \beta x)~/~\partial x = \beta$ et ne dépend pas de $x$ (i.e., $\beta$ est constant).

. . .

Dans un GLM binomial (avec une fonction de lien logit), la probabilité d'un événement est donnée par la fonction logistique :

$$p_{i} = \frac{\exp(\alpha + \beta \cdot x_{i})}{1 + \exp(\alpha + \beta \cdot x_{i})}$$

. . .

Et le taux de changement de $p$ en fonction du prédicteur $x$ est donné par :

$$
\frac{\partial p}{\partial x} = \frac{\beta}{2(1 + cosh(\alpha + \beta \cdot x)}
$$

On voit que la variation sur $p$ due au prédicteur $x$ est fonction du prédicteur $x$... !

## Exemple de régression logistique : La prosocialité chez le chimpanzé

```{r chimp, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/chimp_exp.jpg")
```

## Régression logistique

```{r, echo = TRUE}
library(tidyverse)
library(rethinking)

data(chimpanzees) # see ?chimpanzees for more information on the dataset
df1 <- chimpanzees
str(df1)
```

+ **pulled_left** : 1 lorsque le chimpanzé pousse le levier gauche, 0 sinon 
+ **prosoc_left** : 1 lorsque le levier gauche est associé à l'option prosociale, 0 sinon
+ **condition** : 1 lorsqu'un partenaire est présent, 0 sinon

## Régression logistique 

### Le problème

On cherche à savoir si la présence d'un singe partenaire incite le chimpanzé à appuyer sur le levier prosocial, c'est à dire l'option qui donne de la nourriture aux deux individus. Autrement dit, est-ce qu'il existe une interaction entre l'effet de la latéralité et l'effet de la présence d'un autre chimpanzé sur la probabilité d'actionner le levier gauche.

### Les variables

+ Observations (`pulled_left`) : Ce sont des variables de Bernoulli. Elles prennent comme valeur 0/1. 

+ Prédicteur (`prosoc_left`) : Est-ce que les deux plats sont sur la gauche ou sur la droite ?

+ Prédicteur (`condition`) : Est-ce qu'un partenaire est présent ?

## Régression logistique 

$$
\begin{align}
L_{i} &\sim \mathrm{Binomial}(1, p_{i}) \\
\text{(equivalent to)} \quad L_{i} &\sim \mathrm{Bernoulli}(p_{i}) \\
\text{logit}(p_{i}) &= \alpha \\
\alpha &\sim \mathrm{Normal}(0, \omega) \\
\end{align}
$$

Modèle mathématique sans prédicteur. Comment choisir une valeur pour $\omega$... ?

## Prior predictive check

On écrit le modèle précédent avec `brms` et on échantillonne à partir du prior afin de vérifier que les prédictions du modèle (sur la base du prior seul) correspondent à nos attentes.

```{r mod1, eval = TRUE, echo = TRUE, results = "hide"}
library(brms)

mod1.1 <- brm(
  formula = pulled_left | trials(1) ~ 1,
  family = binomial,
  prior = set_prior("normal(0, 10)", class = "Intercept"),
  data = df1,
  # stores prior samples
  sample_prior = "yes"
  )
```

## Prior predictive check

```{r ppc-mod1.1, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6, out.width = "60%"}
# extracts prior samples
prior_samples(mod1.1) %>%
  # applies the inverse link function
  mutate(p = brms::inv_logit_scaled(Intercept) ) %>%
  ggplot(aes(x = p) ) +
  geom_density(fill = "steelblue", adjust = 0.1) +
  labs(x = "Probabilité a priori de tirer le levier gauche", y = "Densité de probabilité")
```

## Prior predictive check

```{r ppc-mod1.2, eval = TRUE, echo = FALSE, results = "hide", fig.width = 12, fig.height = 6, out.width = "80%"}
mod1.2 <- brm(
  formula = pulled_left | trials(1) ~ 1,
  family = binomial,
  prior = set_prior("normal(0, 1)", class = "Intercept"),
  data = df1,
  sample_prior = "yes"
  )

bind_rows(prior_samples(mod1.1), prior_samples(mod1.2) ) %>% 
  mutate(
    p = inv_logit_scaled(Intercept),
    w = factor(rep(c(10, 1), each = n() / 2), levels = c(10, 1) )
    ) %>%
  ggplot(aes(x = p, fill = w) ) +
  geom_density(alpha = 0.8, adjust = 0.1) +
  scale_fill_manual(expression(italic(omega) ), values = c("steelblue", "blue") ) +
  labs(x = "Probabilité a priori de tirer le levier gauche", y = "Densité de probabilité")
```

## Régression logistique 

L'intercept s'interprète dans l'espace des log-odds... pour l'interpréter comme une probabilité, il faut appliquer la fonction de lien inverse. On peut utiliser la fonction `plogis()`.

```{r, eval = TRUE, echo = TRUE}
#| output-location: fragment
fixed_effects <- fixef(mod1.2) # effets fixes (ou constants)
plogis(fixed_effects) # fonction de lien inverse
```

En moyenne (sans considérer les prédicteurs), il semblerait que les singes aient plus tendance à appuyer sur le levier gauche que sur le levier droit...

## Régression logistique 

```{r, eval = TRUE, echo = TRUE, results = "hide", fig.width = 9, fig.height = 6, out.width = "50%", dev = "png", dpi = 200}
post <- as_draws_df(x = mod1.2)
intercept_samples <- plogis(post$b_Intercept)

posterior_plot(
    samples = intercept_samples, compval = 0.5
    ) +
    labs(x = "Probability of pulling left")
```

## Régression logistique 

Et si on ajoute des prédicteurs... comment choisir une valeur pour $\omega$ ?

$$
\begin{align}
L_{i} &\sim \mathrm{Binomial}(1, p_{i}) \\
\text{logit}(p_{i}) &= \alpha + \beta_{P} P_{i} + \beta_{C} C_{i} + \beta_{PC} P_{i} C_{i} \\
\alpha &\sim \mathrm{Normal}(0, 1) \\
\beta_{P}, \beta_{C}, \beta_{PC} &\sim \mathrm{Normal}(0, \omega) \\
\end{align}
$$

+ $L_{i}$ indique si le singe a poussé le levier gauche (`pulled_left`)
+ $P_{i}$ indique si le coté gauche correspond au coté prosocial
+ $C_{i}$ indique la présence d'un partenaire

## Régression logistique 

```{r mod2, eval = TRUE, echo = TRUE, results = "hide"}
# recoding predictors
df1 <- df1 %>%
  mutate(
    prosoc_left = ifelse(prosoc_left == 1, 0.5, -0.5),
    condition = ifelse(condition == 1, 0.5, -0.5)
    )

priors <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 10)", class = "b")
  )

mod2.1 <- brm(
  formula = pulled_left | trials(1) ~ 1 + prosoc_left * condition,
  family = binomial,
  prior = priors,
  data = df1,
  sample_prior = "yes"
  )
```

## Prior predictive check

```{r ppc-mod2.1, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6, out.width = "50%"}
prior_samples(mod2.1) %>%
  mutate(
    condition1 = plogis(Intercept - 0.5 * b),
    condition2 = plogis(Intercept + 0.5 * b)
    ) %>%
  ggplot(aes(x = condition2 - condition1) ) +
  geom_density(fill = "steelblue", adjust = 0.1) +
  labs(
    x = "Différence dans la probabilité a priori de tirer le levier gauche entre conditions",
    y = "Densité de probabilité"
    )
```

## Régression logistique 

```{r mod2.2, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b")
  )

mod2.2 <- brm(
  formula = pulled_left | trials(1) ~ 1 + prosoc_left * condition,
  family = binomial,
  prior = priors,
  data = df1,
  sample_prior = "yes"
  )
```

## Prior predictive check

```{r ppc-mod2.2, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6, out.width = "50%"}
prior_samples(mod2.2) %>%
  mutate(
    condition1 = plogis(Intercept - 0.5 * b),
    condition2 = plogis(Intercept + 0.5 * b)
    ) %>%
  ggplot(aes(x = condition2 - condition1) ) +
  geom_density(fill = "steelblue", adjust = 0.1) +
  labs(
    x = "Différence dans la probabilité a priori de tirer le levier gauche entre conditions",
    y = "Densité de probabilité"
    )
```

## Régression logistique

```{r, eval = TRUE, echo = TRUE}
summary(mod2.2)
```

## Effet relatif vs. Effet absolu

Le modèle linéaire ne prédit pas directement la probabilité mais le log-odds de la probabilité :

$$
\begin{align}
\text{logit}(p_{i}) &= \log \left(\frac{p_{i}}{1 - p_{i}} \right) = \alpha + \beta x_{i} \\
\end{align}
$$

. . .

On peut donc distinguer et interpréter deux types d'effets.

**Effet relatif** : L'effet relatif porte sur le logarithme du rapport des probabilités. Il indique une *proportion* de changement induit par le prédicteur sur *les chances* de succès (ou plutôt, sur la cote). Cela ne nous dit rien de la probabilité de l'événement, dans l'absolu.

. . .

**Effet absolu** : Effet qui porte directement sur la probabilité d'un événement. Il dépend de tous les paramètres du modèle et nous donne l'impact effectif d'un changement d'une unité d'un prédicteur (dans l'espace des probabilités).

## Effet relatif

Il s'agit d'une **proportion** de changement induit par le prédicteur sur le rapport des chances ou "cote" (*odds*). Illustration avec un modèle sans interaction.

$$ 
\begin{align}
\log\left(\frac{p_{i}}{1 - p_{i}}\right) &= \alpha + \beta x_{i} \\
\frac{p_{i}}{1 - p_{i}} &= \exp(\alpha + \beta x_{i}) \\
\end{align}
$$

. . .

La cote proportionnelle $q$ d'un événement est le nombre par lequel la cote est multipliée lorsque $x_{i}$ augmente d'une unité.

$$
\begin{align}
q = \frac{\exp(\alpha + \beta(x_{i} + 1))}{\exp(\alpha + \beta x_{i})} = \frac{\exp(\alpha) \exp(\beta x_{i}) \exp(\beta)}{\exp(\alpha) \exp(\beta x_{i})} = \exp(\beta)
\end{align}
$$

Lorsque $q = 2$ (par exemple), une augmentation de $x_{i}$ d'une unité génère un doublement de la cote.

## Interprétation de l'effet relatif

L'effet relatif d'un paramètre **dépend également des autres paramètres**. Dans le modèle précédent, le prédicteur `prosoc_left` augmente le log de la cote d'environ 0.54, ce qui se traduit par une augmentation de la cote de $\exp(0.54) \approx 1.72$ soit une augmentation d'environ 72% de la cote.

. . .

Supposons que l'intercept $\alpha = 4$.

+ La probabilité de pousser le levier sans autre considération est de $\text{logit}^{-1}(4) = 0.98$.
+ En considérant l'effet de `prosoc_left`, on obtient $\text{logit}^{-1}(4 + 0.54) \approx 0.99$.

. . .

Une augmentation de 72% sur le log-odds se traduit par une augmentation de seulement 1% sur la probabilité effective... Les effets relatifs peuvent conduire à de mauvaises interprétations lorsqu'on ne considère pas l'échelle de la variable mesurée.

## Interprétation de l'effet relatif

```{r, eval = TRUE, echo = TRUE}
fixef(mod2.2)
```

```{r, eval = TRUE, echo = TRUE, fig.width = 9, fig.height = 6, out.width = "50%", dev = "png", dpi = 200}
post <- as_draws_df(x = mod2.2)

posterior_plot(
    samples = exp(post$b_prosoc_left),
    compval = 1
    ) +
    labs(x = "Odds ratio")
```

## Effet absolu

L'effet absolu dépend de tous les paramètres du modèle et nous donne l'impact effectif d'un changement d'une unité d'un prédicteur (dans l'espace des probabilités).

```{r, eval = TRUE, echo = TRUE}
model_predictions <- fitted(mod2.2) %>%
  data.frame() %>% 
  bind_cols(df1) %>%
  mutate(condition = factor(condition), prosoc_left = factor(prosoc_left) )
```

```{r, eval = TRUE, echo = FALSE, fig.width = 9, fig.height = 6, out.width = "50%"}
model_predictions %>%
  ggplot(aes(
    x = prosoc_left, y = Estimate,
    ymin = Q2.5, ymax = Q97.5, colour = condition
    ) ) +
  geom_hline(yintercept = 0.5, lty = 2) +
  geom_line(
    aes(group = condition),
    size = 1,
    position = position_dodge(0.2)
    ) +
  geom_pointrange(
    aes(color = condition),
    size = 1, fatten = 2, show.legend = TRUE,
    position = position_dodge(0.2)
    ) +
  ylim(0, 1) +
  scale_x_discrete(labels = c("Non", "Oui") ) +
  scale_colour_discrete(labels = c("Seul", "Social") ) +
  labs(
  x = "Est-ce que l'option prosociale était à gauche ?",
  y = "Probabilité de tirer le levier gauche"
  )
```

## Régression binomiale agrégée 

Ces données représentent le nombre de candidatures à l'université de Berkeley par sexe et par département. Chaque candidature est acceptée ou rejetée et les résultats sont agrégés par département et par sexe.

```{r eval = TRUE, echo = TRUE}
library(rethinking)
data(UCBadmit)
(df2 <- UCBadmit)
```

Existe-t-il un biais de recrutement lié au sexe ?

## Régression binomiale agrégée 

On va construire un modèle de la décision d'admission en prenant comme prédicteur le sexe du candidat.

$$
\begin{align}
\text{admit}_{i} &\sim \mathrm{Binomial}(n_{i}, p_{i}) \\
\text{logit}(p_i) &= \alpha + \beta_{m} m_{i} \\
\alpha &\sim \mathrm{Normal}(0, 1) \\
\beta_{m} &\sim \mathrm{Normal}(0, 1) \\
\end{align}
$$

. . .

Les variables :

+ $\text{admit}_{i}$ : Le nombre de candidatures acceptées (`admit`)
+ $n_{i}$ : Le nombre total de candidatures (`applications`)
+ $m_{i}$ : Le sexe du candidat (`1 = male`)

## Régression binomiale agrégée 

```{r mod3, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(set_prior("normal(0, 1)", class = "Intercept") )

mod3 <- brm(
  formula = admit | trials(applications) ~ 1,
  family = binomial(link = "logit"),
  prior = priors,
  data = df2,
  sample_prior = "yes"
  )
```

## Régression binomiale agrégée 

```{r mod4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b")
  )

# dummy-coding
df2$male <- ifelse(df2$applicant.gender == "male", 1, 0)

mod4 <- brm(
  formula = admit | trials(applications) ~ 1 + male,
  family = binomial(link = "logit"),
  prior = priors,
  data = df2,
  sample_prior = "yes"
  )
```

## Régression binomiale agrégée 

```{r eval = TRUE, echo = TRUE}
summary(mod4)
```

Être un homme semble être un avantage... ! Le rapport des cotes est de $\exp(0.61) \approx 1.84$.

## Régression binomiale agrégée 

Calculons la différence de probabilité d'admission entre hommes et femmes.

```{r eval = TRUE, echo = TRUE, fig.width = 8, fig.height = 6, out.width = "50%", dev = "png", dpi = 200}
post <- as_draws_df(x = mod4)
p.admit.male <- plogis(post$b_Intercept + post$b_male)
p.admit.female <- plogis(post$b_Intercept)
diff.admit <- p.admit.male - p.admit.female
posterior_plot(samples = diff.admit, compval = 0)
```

## Visualiser les prédictions du modèle

On examine les prédictions du modèle par département.

```{r eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# pp_check(mod4, type = "intervals", nsamples = 1e2, prob = 0.5, prob_outer = 0.95) +
#   scale_x_continuous(breaks = 1:12, limits = c(1, 12) ) +
#   theme_bw(base_size = 20) +
#   labs(x = "Sexe / Département", y = "Nombre d'admissions")

df2 <- df2 %>% mutate(case = factor(1:12) )

p <- 
  predict(mod4) %>% 
  as_tibble() %>% 
  bind_cols(df2)

d_text <-
  df2 %>%
  group_by(dept) %>%
  summarise(
    case  = mean(as.numeric(case) ),
    admit = mean(admit / applications) + 0.05
    )

ggplot(data = df2, aes(x = case, y = admit / applications) ) +
  geom_pointrange(
    data = p, 
    aes(
      y = Estimate / applications,
      ymin = Q2.5 / applications ,
      ymax = Q97.5 / applications
      ),
    shape = 1, alpha = 0.5
    ) +
  geom_point(color = "steelblue") +
  geom_line(
    aes(group = dept),
    color = "steelblue"
    ) +
  geom_text(
    data = d_text,
    aes(y = admit, label = dept),
    color = "steelblue"
    ) +
  coord_cartesian(ylim = 0:1) +
  scale_x_discrete(
    breaks = 1:12,
    labels = rep(c("male", "female"), 6)
    ) +
  labs(
    x = "",
    y = "Probabilité d'admission",
    title = "Posterior predictive check"
    )
```

## Régression binomiale agrégée 

Les prédictions du modèle sont très mauvaises... Il n'y a que deux départements pour lesquels les femmes ont de moins bonnes prédictions que les hommes (C et E) alors que le modèle prédit une probabilité d'admission plus basse pour tous les départements...

. . .

Le problème est double :

+ Les hommes et les femmes ne postulent pas aux mêmes départements
+ Les départements n'ont pas tous les mêmes effectifs

. . .

C'est le paradoxe de Simpson... remarques :

+ La distribution postérieure seule n'aurait pas permis de détecter ce problème
+ C'est l'étude des prédictions du modèle qui nous a permis de mettre le doigt sur le problème...

## Régression binomiale agrégée 

On construit donc un modèle de la décision d'admission en fonction du genre, *au sein de chaque département*.

$$
\begin{align}
\text{admit}_{i} &\sim \mathrm{Binomial}(n_{i}, p_{i}) \\
\text{logit}(p_i) &= \alpha_{\text{dept}[i]} + \beta_{m} m_{i} \\
\alpha_{\text{dept}[i]} &\sim \mathrm{Normal}(0, 1) \\
\beta_{m} &\sim \mathrm{Normal}(0, 1) \\
\end{align}
$$

## Régression binomiale aggrégée 

```{r eval = TRUE, echo = TRUE, results = "hide"}
# modèle sans prédicteur
mod5 <- brm(
  admit | trials(applications) ~ 0 + dept,
  family = binomial(link = "logit"),
  prior = set_prior("normal(0, 1)", class = "b"),
  data = df2
  )

# modèle avec prédicteur
mod6 <- brm(
  admit | trials(applications) ~ 0 + dept + male,
  family = binomial(link = "logit"),
  prior = set_prior("normal(0, 1)", class = "b"),
  data = df2
  )
```

## Régression binomiale aggrégée 

```{r eval = TRUE, echo = TRUE}
summary(mod6)
```

## Régression binomiale agrégée 

```{r eval = TRUE, echo = TRUE}
fixef(mod6)
```

Maintenant, la prédiction pour $\beta_{m}$ va dans l'autre sens... La rapport des cotes (odds ratio) est de $\exp(-0.1)$ soit 90% de la cote des femmes.

## Régression binomiale agrégée 

```{r eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
predict(mod6) %>%
  as_tibble() %>% 
  bind_cols(df2) %>%
  ggplot(aes(x = case, y = admit / applications) ) +
  geom_pointrange(
    aes(
      y = Estimate / applications,
      ymin = Q2.5 / applications,
      ymax = Q97.5 / applications
      ),
    color = "steelblue",
    shape = 1, alpha = 0.5
    ) +
  geom_point(color = "steelblue") +
  geom_line(
    aes(group = dept),
    color = "steelblue"
    ) +
  geom_text(
    data = d_text,
    aes(y = admit, label = dept),
    color = "steelblue"
    ) +
  coord_cartesian(ylim = 0:1) +
  scale_x_discrete(
    breaks = 1:12,
    labels = rep(c("male", "female"), 6)
    ) +
  labs(
    x = "",
    y = "Probabilité d'admission",
    title = "Posterior predictive check"
    )
```

## Conclusions 

Les hommes et les femmes ne postulent pas aux mêmes départements et les départements varient par leur probabilité d'admission. En l'occurrence, les femmes ont plus postulé aux départements E et F (avec une probabilité d'admission plus faible) et ont moins postulé aux départements A ou B, avec une probabilité d'admission plus haute.

. . .

Pour évaluer l'effet du sexe sur la probabilité d'admission, il faut donc se poser la question suivante : "Quelle est la différence de probabilité d'admission entre hommes et femmes *au sein de chaque département* ?" (plutôt que de manière générale).

. . .

Retenir que le modèle de régression peut être généralisé à différents modèles de génération des données (i.e., différentes distributions de probabilité, comme la distribution Normale, Binomiale, Poisson, etc) et que l'espace des paramètres peut être "connecté" à l'espace des prédicteurs (variables mesurées) grâce à des fonctions de lien (e.g., la fonction logarithme, exponentielle, logit, etc).

. . .

Retenir la distinction entre **effet relatif** (e.g., un changement de cote) et **effet absolu** (e.g., une différence de probabilité).

## Travaux pratiques - Absentéisme expérimental

Travailler avec des sujets humains implique un minimum de coopération réciproque. Mais ce n'est pas toujours le cas. Une partie non-négligeable des étudiants qui s'inscrivent pour passer des expériences de Psychologie ne se présentent pas le jour prévu... On a voulu estimer la **probabilité de présence d'un étudiant inscrit** en fonction de l'envoi (ou non) d'un mail de rappel (cet exemple est présenté en détails dans deux blogposts, accessibles [ici](http://www.barelysignificant.com/post/absenteeism/), et [ici](http://www.barelysignificant.com/post/absenteeism2/)).

```{r eval = TRUE, echo = TRUE}
library(imsb)
df3 <- open_data(absence)
df3 %>% sample_frac %>% head(10)
```

## Travaux pratiques

1. **Quelle est la probabilité qu'un participant, qui s'est inscrit de son propre chef, vienne effectivement passer l'expérience ?**
2. Quel est l'effet du rappel ?
3. Quel est l'effet du mode d'inscription ?
4. Quel est l'effet conjoint de ces deux prédicteurs ?

## Travaux pratiques

Écrire le modèle qui prédit la présence d'un participant sans prédicteur.

$$
\begin{aligned}
y_{i} &\sim \mathrm{Binomial}(n_{i}, p_{i}) \\
\text{logit}(p_{i}) &= \alpha \\
\alpha &\sim \mathrm{Normal}(0, 1) \\
\end{aligned}
$$

## Travaux pratiques

```{r mod7, eval = TRUE, echo = TRUE, results = "hide"}
mod7 <- brm(
    presence | trials(total) ~ 1,
    family = binomial(link = "logit"),
    prior = set_prior("normal(0, 1)", class = "Intercept"),
    data = df3,
    cores = parallel::detectCores()
    )
```

```{r, eval = TRUE, echo = TRUE}
fixef(mod7) # effet relatif (log de la cote)
fixef(mod7) %>% plogis # effet absolu (probabilité de présence)
```

## Travaux pratiques

1. Quelle est la probabilité qu'un participant, qui s'est inscrit de son propre chef, vienne effectivement passer l'expérience ?
2. **Quel est l'effet du rappel ?**
3. Quel est l'effet du mode d'inscription ?
4. Quel est l'effet conjoint de ces deux prédicteurs ?

## Travaux pratiques

On commence par re-coder en dummy variables le *reminder* et l'*inscription*.

```{r eval = TRUE, echo = TRUE}
df3 <-
  df3 %>%
  mutate(
    reminder = ifelse(reminder == "no", 0, 1),
    inscription = ifelse(inscription == "panel", 0, 1)
    )

head(df3, n = 10)
```

## Travaux pratiques

Écrire le modèle qui prédit la présence en fonction du rappel.

$$
\begin{aligned}
y_{i} &\sim \mathrm{Binomial}(n_{i}, p_{i}) \\
\text{logit}(p_{i}) &= \alpha + \beta \times \text{reminder}_{i} \\
\alpha &\sim \mathrm{Normal}(0, 1) \\
\beta &\sim \mathrm{Normal}(0, 1) \\
\end{aligned}
$$

## Travaux pratiques

Écrire le modèle qui prédit la présence en fonction du rappel.

```{r mod8, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b")
  )

mod8 <- brm(
    presence | trials(total) ~ 1 + reminder,
    family = binomial(link = "logit"),
    prior = priors,
    data = df3,
    cores = parallel::detectCores()
    )
```

## Travaux pratiques

Quel est l'effet **relatif** du mail de rappel ?

```{r eval = TRUE, echo = TRUE}
exp(fixef(mod8)[2]) # odds ratio between no-reminder and reminder
```

Envoyer un rappel augmente proportionnellement les chances de présence (i.e., augmente la cote) par environ $3$.

## Travaux pratiques 

Quel est l'effet **absolu** du mail de rappel ?

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5, dev = "png", dpi = 200}
post <- as_draws_df(x = mod8) # extracting posterior samples
p.no <- plogis(post$b_Intercept) # mean probability of presence when no reminder
p.yes <- plogis(post$b_Intercept + post$b_reminder) # mean probability of presence when reminder
posterior_plot(samples = p.yes - p.no, compval = 0, usemode = TRUE) # plotting it
```

## Travaux pratiques 

```{r eval = TRUE, echo = TRUE, fig.width = 8, fig.height = 4}
library(tidybayes)
library(modelr)

df3 %>%
  group_by(total) %>%
  data_grid(reminder = seq_range(reminder, n = 1e2) ) %>%
  add_fitted_draws(mod8, newdata = ., n = 100, scale = "linear") %>%
  mutate(estimate = plogis(.value) ) %>%
  group_by(reminder, .draw) %>%
  summarise(estimate = mean(estimate) ) %>%
  ggplot(aes(x = reminder, y = estimate, group = .draw) ) +
  geom_hline(yintercept = 0.5, lty = 2) +
  geom_line(aes(y = estimate, group = .draw), size = 0.5, alpha = 0.1) +
  ylim(0, 1) +
  labs(x = "Mail de rappel", y = "Probabilité de présence")
```

## Travaux pratiques

1. Quelle est la probabilité qu'un participant, qui s'est inscrit de son propre chef, vienne effectivement passer l'expérience ?
2. Quel est l'effet du rappel ?
3. **Quel est l'effet du mode d'inscription ?**
4. Quel est l'effet conjoint de ces deux prédicteurs ?

## Travaux pratiques

Écrire le modèle qui prédit la présence en fonction du mode d'inscription.

$$
\begin{aligned}
y_{i} &\sim \mathrm{Binomial}(n_{i}, p_{i}) \\
\text{logit}(p_{i}) &= \alpha + \beta \times \text{inscription}_{i} \\
\alpha &\sim \mathrm{Normal}(0, 1) \\
\beta &\sim \mathrm{Normal}(0, 1) \\
\end{aligned}
$$

## Travaux pratiques

```{r mod9, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b")
  )

mod9 <- brm(
    presence | trials(total) ~ 1 + inscription,
    family = binomial(link = "logit"),
    prior = priors,
    data = df3,
    cores = parallel::detectCores()
    )
```

## Travaux pratiques

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5, dev = "png", dpi = 200}
post <- as_draws_df(x = mod9)
p.panel <- plogis(post$b_Intercept) # mean probability of presence for panel
p.doodle <- plogis(post$b_Intercept + post$b_inscription) # mean probability of presence for doodle
posterior_plot(samples = p.panel - p.doodle, compval = 0, usemode = TRUE) # plotting it
```

La probabilité de présence est augmentée de $0.17$ lorsque l'on s'inscrit sur un panel comparativement à une inscription sur un doodle (effet légèrement plus faible que pour le rappel).

## Travaux pratiques

1. Quelle est la probabilité qu'un participant, qui s'est inscrit de son propre chef, vienne effectivement passer l'expérience ?
2. Quel est l'effet du rappel ?
3. Quel est l'effet du mode d'inscription ?
4. **Quel est l'effet conjoint de ces deux prédicteurs ?**

## Travaux pratiques

Écrire le modèle complet.

$$
\begin{aligned}
y_{i} &\sim \mathrm{Binomial}(n_{i}, p_{i}) \\
\text{logit}(p_{i}) &= \alpha + \beta_{1} \times \text{reminder}_{i} + \beta_{2} \times \text{inscription}_{i} \\
\alpha &\sim \mathrm{Normal}(0, 1) \\
\beta_{1}, \beta_{2} &\sim \mathrm{Normal}(0, 1) \\
\end{aligned}
$$

## Travaux pratiques

```{r mod10, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  set_prior("normal(0, 1)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b")
  )

mod10 <- brm(
    presence | trials(total) ~ 1 + reminder + inscription,
    family = binomial(link = "logit"),
    prior = priors,
    data = df3,
    cores = parallel::detectCores()
    )
```

## Travaux pratiques

```{r eval = TRUE, echo = TRUE}
summary(mod10)
```

## Travaux pratiques

Le mode d'inscription et le mail de rappel semblent avoir moins d'effet dans le modèle complet que dans les modèles simples... pourquoi ?

```{r eval = TRUE, echo = TRUE}
fixef(mod8) %>% exp
fixef(mod9) %>% exp
fixef(mod10) %>% exp
```

## Travaux pratiques

On a déjà rencontré ce cas de figure (cf. Cours n°04). Lorsque deux prédicteurs contiennent une part d'information commune, l'estimation des pentes est corrêlée...

```{r eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
as_draws_df(x = mod10) %>%
    ggplot(aes(b_reminder, b_inscription) ) +
    geom_point(size = 3, pch = 21, alpha = 0.8, color = "white", fill = "black")
```

## Travaux pratiques

En effet, les données ont été collectées par deux expérimentateurs. L'un d'entre eux a recruté tous ses participants via doodle, et n'envoyait pas souvent de mail de rappel. Le deuxième expérimentateur a recruté tous ses participants via un panneau physique présent dans le laboratoire et envoyait systématiquement un mail de rappel. Autrement dit, ces deux variables sont presque parfaitement confondues.

```{r eval = TRUE, echo = TRUE}
open_data(absence) %>%
  sample_frac() %>%
  group_by(inscription, reminder) %>%
  summarise(n = sum(total) ) %>%
  spread(key = reminder, value = n) %>%
  data.frame()
```
