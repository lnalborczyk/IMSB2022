<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 2 Modèle beta-binomial | Notes de cours - Introduction à la modélisation statistique bayésienne</title>
  <meta name="description" content="<p>Ce document regroupe les notes de l’édition 2022 de la formation doctorale
‘Introduction à la modélisation statistique bayésienne’, co-organisée par le collège
des écoles doctorales de l’Université Grenoble Alpes et la Maison de la Modélisation
et de la Simulation, Nanoscience et Environnement (MaiMoSiNE).</p>" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 2 Modèle beta-binomial | Notes de cours - Introduction à la modélisation statistique bayésienne" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://www.barelysignificant.com/IMSB2022/_notes/./figures/cover_distributions.png" />
  <meta property="og:description" content="<p>Ce document regroupe les notes de l’édition 2022 de la formation doctorale
‘Introduction à la modélisation statistique bayésienne’, co-organisée par le collège
des écoles doctorales de l’Université Grenoble Alpes et la Maison de la Modélisation
et de la Simulation, Nanoscience et Environnement (MaiMoSiNE).</p>" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 2 Modèle beta-binomial | Notes de cours - Introduction à la modélisation statistique bayésienne" />
  
  <meta name="twitter:description" content="<p>Ce document regroupe les notes de l’édition 2022 de la formation doctorale
‘Introduction à la modélisation statistique bayésienne’, co-organisée par le collège
des écoles doctorales de l’Université Grenoble Alpes et la Maison de la Modélisation
et de la Simulation, Nanoscience et Environnement (MaiMoSiNE).</p>" />
  <meta name="twitter:image" content="https://www.barelysignificant.com/IMSB2022/_notes/./figures/cover_distributions.png" />

<meta name="author" content="Ladislas Nalborczyk" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="./figures/cover_distributions.png" type="image/x-icon" />
<link rel="prev" href="1-introduction.html"/>
<link rel="next" href="3-linear-regression1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<script src="js/hideOutput.js"></script>

<!-- Mathjax -->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/default.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>
-->

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction à la modélisation statistique bayésienne</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction à l’inférence bayésienne</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1-introduction.html"><a href="1-introduction.html#quest-ce-quune-probabilité"><i class="fa fa-check"></i><b>1.1</b> Qu’est-ce qu’une probabilité ?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="1-introduction.html"><a href="1-introduction.html#axiomes-des-probabilités"><i class="fa fa-check"></i><b>1.1.1</b> Axiomes des probabilités</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-introduction.html"><a href="1-introduction.html#interprétations-probabilistes"><i class="fa fa-check"></i><b>1.1.2</b> Interprétations probabilistes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-introduction.html"><a href="1-introduction.html#logique-et-raisonnement-scientifique"><i class="fa fa-check"></i><b>1.2</b> Logique et raisonnement scientifique</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-introduction.html"><a href="1-introduction.html#introduction-à-la-logique"><i class="fa fa-check"></i><b>1.2.1</b> Introduction à la logique</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-introduction.html"><a href="1-introduction.html#quelques-syllogismes-connus"><i class="fa fa-check"></i><b>1.2.2</b> Quelques syllogismes connus</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-introduction.html"><a href="1-introduction.html#quest-ce-quune-théorie-scientifique"><i class="fa fa-check"></i><b>1.2.3</b> Qu’est-ce qu’une théorie scientifique ?</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-introduction.html"><a href="1-introduction.html#test-dhypothèse-nulle-et-raisonnement-scientifique"><i class="fa fa-check"></i><b>1.2.4</b> Test d’hypothèse nulle et raisonnement scientifique</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-introduction.html"><a href="1-introduction.html#lapproche-par-comparaison-de-modèles"><i class="fa fa-check"></i><b>1.2.5</b> L’approche par comparaison de modèles</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-introduction.html"><a href="1-introduction.html#problème-du-sac-de-billes-mcelreath_statistical_2016"><i class="fa fa-check"></i><b>1.3</b> Problème du sac de billes <span class="citation">(<span>McElreath, 2016b</span>)</span></a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-introduction.html"><a href="1-introduction.html#énumérer-les-possibilités"><i class="fa fa-check"></i><b>1.3.1</b> Énumérer les possibilités</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-introduction.html"><a href="1-introduction.html#accumulation-dévidence"><i class="fa fa-check"></i><b>1.3.2</b> Accumulation d’évidence</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-introduction.html"><a href="1-introduction.html#incorporer-un-prior"><i class="fa fa-check"></i><b>1.3.3</b> Incorporer un prior</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-introduction.html"><a href="1-introduction.html#des-énumérations-aux-probabilités"><i class="fa fa-check"></i><b>1.3.4</b> Des énumérations aux probabilités</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-introduction.html"><a href="1-introduction.html#rappels-de-théorie-des-probabilités"><i class="fa fa-check"></i><b>1.4</b> Rappels de théorie des probabilités</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="1-introduction.html"><a href="1-introduction.html#probabilité-conjointe"><i class="fa fa-check"></i><b>1.4.1</b> Probabilité conjointe</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-introduction.html"><a href="1-introduction.html#probabilité-marginale"><i class="fa fa-check"></i><b>1.4.2</b> Probabilité marginale</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-introduction.html"><a href="1-introduction.html#probabilité-conditionnelle"><i class="fa fa-check"></i><b>1.4.3</b> Probabilité conditionnelle</a></li>
<li class="chapter" data-level="1.4.4" data-path="1-introduction.html"><a href="1-introduction.html#dérivation-du-théorème-de-bayes"><i class="fa fa-check"></i><b>1.4.4</b> Dérivation du théorème de Bayes</a></li>
<li class="chapter" data-level="1.4.5" data-path="1-introduction.html"><a href="1-introduction.html#loi-de-probabilité-cas-discret"><i class="fa fa-check"></i><b>1.4.5</b> Loi de probabilité, cas discret</a></li>
<li class="chapter" data-level="1.4.6" data-path="1-introduction.html"><a href="1-introduction.html#loi-de-probabilité-cas-continu"><i class="fa fa-check"></i><b>1.4.6</b> Loi de probabilité, cas continu</a></li>
<li class="chapter" data-level="1.4.7" data-path="1-introduction.html"><a href="1-introduction.html#aparté-quest-ce-quune-intégrale"><i class="fa fa-check"></i><b>1.4.7</b> Aparté, qu’est-ce qu’une intégrale ?</a></li>
<li class="chapter" data-level="1.4.8" data-path="1-introduction.html"><a href="1-introduction.html#notations-terminologie"><i class="fa fa-check"></i><b>1.4.8</b> Notations, terminologie</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-introduction.html"><a href="1-introduction.html#quelques-exemples-dapplication"><i class="fa fa-check"></i><b>1.5</b> Quelques exemples d’application</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="1-introduction.html"><a href="1-introduction.html#diagnostique-médical-gigerenzer-2002"><i class="fa fa-check"></i><b>1.5.1</b> Diagnostique médical (Gigerenzer, 2002)</a></li>
<li class="chapter" data-level="1.5.2" data-path="1-introduction.html"><a href="1-introduction.html#problème-de-monty-hall"><i class="fa fa-check"></i><b>1.5.2</b> Problème de Monty Hall</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html"><i class="fa fa-check"></i><b>2</b> Modèle beta-binomial</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#coefficient-binomial"><i class="fa fa-check"></i><b>2.1</b> Coefficient binomial</a></li>
<li class="chapter" data-level="2.2" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#le-modèle-beta-binomial"><i class="fa fa-check"></i><b>2.2</b> Le modèle Beta-Binomial</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#loi-de-bernoulli"><i class="fa fa-check"></i><b>2.2.1</b> Loi de Bernoulli</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#processus-de-bernoulli"><i class="fa fa-check"></i><b>2.2.2</b> Processus de Bernoulli</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#processus-de-bernoulli-1"><i class="fa fa-check"></i><b>2.2.3</b> Processus de Bernoulli</a></li>
<li class="chapter" data-level="2.2.4" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#coefficient-binomial-1"><i class="fa fa-check"></i><b>2.2.4</b> Coefficient binomial</a></li>
<li class="chapter" data-level="2.2.5" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#loi-binomiale"><i class="fa fa-check"></i><b>2.2.5</b> Loi binomiale</a></li>
<li class="chapter" data-level="2.2.6" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#générer-des-données-à-partir-dune-distribution-binomiale"><i class="fa fa-check"></i><b>2.2.6</b> Générer des données à partir d’une distribution binomiale</a></li>
<li class="chapter" data-level="2.2.7" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#définition-du-modèle-likelihood"><i class="fa fa-check"></i><b>2.2.7</b> Définition du modèle (likelihood)</a></li>
<li class="chapter" data-level="2.2.8" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#vraisemblance-versus-probabilité"><i class="fa fa-check"></i><b>2.2.8</b> Vraisemblance versus probabilité</a></li>
<li class="chapter" data-level="2.2.9" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#définition-du-prior"><i class="fa fa-check"></i><b>2.2.9</b> Définition du prior</a></li>
<li class="chapter" data-level="2.2.10" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#la-distribution-beta"><i class="fa fa-check"></i><b>2.2.10</b> La distribution Beta</a></li>
<li class="chapter" data-level="2.2.11" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#interprétation-des-paramètres-du-prior-beta"><i class="fa fa-check"></i><b>2.2.11</b> Interprétation des paramètres du prior Beta</a></li>
<li class="chapter" data-level="2.2.12" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#prior-conjugué"><i class="fa fa-check"></i><b>2.2.12</b> Prior conjugué</a></li>
<li class="chapter" data-level="2.2.13" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#dérivation-analytique-de-la-distribution-a-posteriori"><i class="fa fa-check"></i><b>2.2.13</b> Dérivation analytique de la distribution a posteriori</a></li>
<li class="chapter" data-level="2.2.14" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#un-exemple-pour-digérer"><i class="fa fa-check"></i><b>2.2.14</b> Un exemple pour digérer</a></li>
<li class="chapter" data-level="2.2.15" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#influence-du-prior-sur-la-distribution-postérieure"><i class="fa fa-check"></i><b>2.2.15</b> Influence du prior sur la distribution postérieure</a></li>
<li class="chapter" data-level="2.2.16" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#ce-quil-faut-retenir"><i class="fa fa-check"></i><b>2.2.16</b> Ce qu’il faut retenir</a></li>
<li class="chapter" data-level="2.2.17" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#la-vraisemblance-marginale-the-devil-is-in-the-denominator"><i class="fa fa-check"></i><b>2.2.17</b> La vraisemblance marginale (the devil is in the denominator)</a></li>
<li class="chapter" data-level="2.2.18" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#la-distribution-postérieure-solution-analytique"><i class="fa fa-check"></i><b>2.2.18</b> La distribution postérieure, solution analytique</a></li>
<li class="chapter" data-level="2.2.19" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#la-distribution-postérieure-grid-method"><i class="fa fa-check"></i><b>2.2.19</b> La distribution postérieure, grid method</a></li>
<li class="chapter" data-level="2.2.20" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#échantillonner-la-distribution-postérieure"><i class="fa fa-check"></i><b>2.2.20</b> Échantillonner la distribution postérieure</a></li>
<li class="chapter" data-level="2.2.21" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#la-distribution-postérieure-résumé"><i class="fa fa-check"></i><b>2.2.21</b> La distribution postérieure, résumé</a></li>
<li class="chapter" data-level="2.2.22" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#utiliser-les-échantillons-pour-résumer-la-distribution-postérieure"><i class="fa fa-check"></i><b>2.2.22</b> Utiliser les échantillons pour résumer la distribution postérieure</a></li>
<li class="chapter" data-level="2.2.23" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#highest-density-interval-hdi"><i class="fa fa-check"></i><b>2.2.23</b> Highest density interval (HDI)</a></li>
<li class="chapter" data-level="2.2.24" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#region-of-practical-equivalence-rope"><i class="fa fa-check"></i><b>2.2.24</b> Region of practical equivalence (ROPE)</a></li>
<li class="chapter" data-level="2.2.25" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#model-checking"><i class="fa fa-check"></i><b>2.2.25</b> Model checking</a></li>
<li class="chapter" data-level="2.2.26" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#posterior-predictive-checking"><i class="fa fa-check"></i><b>2.2.26</b> Posterior predictive checking</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-beta-binomial.html"><a href="2-beta-binomial.html#conclusions"><i class="fa fa-check"></i><b>2.3</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html"><i class="fa fa-check"></i><b>3</b> Modèle de régression linéaire</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#langage-de-la-modélisation"><i class="fa fa-check"></i><b>3.1</b> Langage de la modélisation</a></li>
<li class="chapter" data-level="3.2" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#un-premier-modèle"><i class="fa fa-check"></i><b>3.2</b> Un premier modèle</a></li>
<li class="chapter" data-level="3.3" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#loi-normale"><i class="fa fa-check"></i><b>3.3</b> Loi normale</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#doù-vient-la-loi-normale"><i class="fa fa-check"></i><b>3.3.1</b> D’où vient la loi normale ?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#modèle-gaussien"><i class="fa fa-check"></i><b>3.4</b> Modèle gaussien</a></li>
<li class="chapter" data-level="3.5" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#visualiser-le-prior"><i class="fa fa-check"></i><b>3.5</b> Visualiser le prior</a></li>
<li class="chapter" data-level="3.6" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#échantillonner-à-partir-du-prior"><i class="fa fa-check"></i><b>3.6</b> Échantillonner à partir du prior</a></li>
<li class="chapter" data-level="3.7" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#fonction-de-vraisemblance"><i class="fa fa-check"></i><b>3.7</b> Fonction de vraisemblance</a></li>
<li class="chapter" data-level="3.8" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#distribution-postérieure"><i class="fa fa-check"></i><b>3.8</b> Distribution postérieure</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#distribution-postérieure---grid-approximation"><i class="fa fa-check"></i><b>3.8.1</b> Distribution postérieure - grid approximation</a></li>
<li class="chapter" data-level="3.8.2" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#distribution-postérieure---distributions-marginales"><i class="fa fa-check"></i><b>3.8.2</b> Distribution postérieure - distributions marginales</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#introduction-à-brms"><i class="fa fa-check"></i><b>3.9</b> Introduction à brms</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#rappels-de-syntaxe"><i class="fa fa-check"></i><b>3.9.1</b> Rappels de syntaxe</a></li>
<li class="chapter" data-level="3.9.2" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#quelques-fonctions-utiles"><i class="fa fa-check"></i><b>3.9.2</b> Quelques fonctions utiles</a></li>
<li class="chapter" data-level="3.9.3" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#un-premier-exemple"><i class="fa fa-check"></i><b>3.9.3</b> Un premier exemple</a></li>
<li class="chapter" data-level="3.9.4" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#en-utilisant-notre-prior"><i class="fa fa-check"></i><b>3.9.4</b> En utilisant notre prior</a></li>
<li class="chapter" data-level="3.9.5" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#en-utilisant-un-prior-plus-informatif"><i class="fa fa-check"></i><b>3.9.5</b> En utilisant un prior plus informatif</a></li>
<li class="chapter" data-level="3.9.6" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#précision-du-prior-heuristique"><i class="fa fa-check"></i><b>3.9.6</b> Précision du prior (heuristique)</a></li>
<li class="chapter" data-level="3.9.7" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#récupérer-et-visualiser-les-échantillons-de-la-distribution-postérieure"><i class="fa fa-check"></i><b>3.9.7</b> Récupérer et visualiser les échantillons de la distribution postérieure</a></li>
<li class="chapter" data-level="3.9.8" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#récupérer-les-échantillons-de-la-distribution-postérieure"><i class="fa fa-check"></i><b>3.9.8</b> Récupérer les échantillons de la distribution postérieure</a></li>
<li class="chapter" data-level="3.9.9" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#visualiser-la-distribution-postérieure"><i class="fa fa-check"></i><b>3.9.9</b> Visualiser la distribution postérieure</a></li>
<li class="chapter" data-level="3.9.10" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#visualiser-la-distribution-postérieure-1"><i class="fa fa-check"></i><b>3.9.10</b> Visualiser la distribution postérieure</a></li>
<li class="chapter" data-level="3.9.11" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#ajouter-un-prédicteur"><i class="fa fa-check"></i><b>3.9.11</b> Ajouter un prédicteur</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#régression-linéaire-à-un-prédicteur-continu"><i class="fa fa-check"></i><b>3.10</b> Régression linéaire à un prédicteur continu</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#différentes-notations-équivalentes"><i class="fa fa-check"></i><b>3.10.1</b> Différentes notations équivalentes</a></li>
<li class="chapter" data-level="3.10.2" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#représenter-les-prédictions-du-modèle"><i class="fa fa-check"></i><b>3.10.2</b> Représenter les prédictions du modèle</a></li>
<li class="chapter" data-level="3.10.3" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#représenter-lincertitude-sur-mu-via-fitted"><i class="fa fa-check"></i><b>3.10.3</b> Représenter l’incertitude sur <span class="math inline">\(\mu\)</span> via fitted()</a></li>
<li class="chapter" data-level="3.10.4" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#intervalles-de-prédiction-incorporer-sigma"><i class="fa fa-check"></i><b>3.10.4</b> Intervalles de prédiction (incorporer <span class="math inline">\(\sigma\)</span>)</a></li>
<li class="chapter" data-level="3.10.5" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#deux-types-dincertitude"><i class="fa fa-check"></i><b>3.10.5</b> Deux types d’incertitude</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#régression-polynomiale"><i class="fa fa-check"></i><b>3.11</b> Régression polynomiale</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#modèle-de-régression-polynomiale"><i class="fa fa-check"></i><b>3.11.1</b> Modèle de régression polynomiale</a></li>
<li class="chapter" data-level="3.11.2" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#représenter-les-prédictions-du-modèle-1"><i class="fa fa-check"></i><b>3.11.2</b> Représenter les prédictions du modèle</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#modèle-de-régression-taille-deffet"><i class="fa fa-check"></i><b>3.12</b> Modèle de régression, taille d’effet</a></li>
<li class="chapter" data-level="3.13" data-path="3-linear-regression1.html"><a href="3-linear-regression1.html#conclusions-1"><i class="fa fa-check"></i><b>3.13</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html"><i class="fa fa-check"></i><b>4</b> Modèle de régression linéaire, suite</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#régression-multiple"><i class="fa fa-check"></i><b>4.1</b> Régression multiple</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#associations-fortuites"><i class="fa fa-check"></i><b>4.1.1</b> Associations fortuites</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#régression-multiple-1"><i class="fa fa-check"></i><b>4.1.2</b> Régression multiple</a></li>
<li class="chapter" data-level="4.1.3" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#toujours-plus-de-prédicteurs"><i class="fa fa-check"></i><b>4.1.3</b> Toujours plus de prédicteurs</a></li>
<li class="chapter" data-level="4.1.4" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#prédicteurs-catégoriels"><i class="fa fa-check"></i><b>4.1.4</b> Prédicteurs catégoriels</a></li>
<li class="chapter" data-level="4.1.5" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#prédicteurs-catégoriels-nombre-de-catégories-3"><i class="fa fa-check"></i><b>4.1.5</b> Prédicteurs catégoriels, nombre de catégories &gt; 3</a></li>
<li class="chapter" data-level="4.1.6" data-path="4-linear-regression2.html"><a href="4-linear-regression2.html#interaction"><i class="fa fa-check"></i><b>4.1.6</b> Interaction</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Annexes</b></span></li>
<li class="chapter" data-level="A" data-path="A-glossaire.html"><a href="A-glossaire.html"><i class="fa fa-check"></i><b>A</b> Glossaire</a></li>
<li class="chapter" data-level="B" data-path="B-notations.html"><a href="B-notations.html"><i class="fa fa-check"></i><b>B</b> Notations</a></li>
<li class="chapter" data-level="" data-path="bibliographie.html"><a href="bibliographie.html"><i class="fa fa-check"></i>Bibliographie</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank"> Powered by bookdown </a></li>
<li><a href="http://www.barelysignificant.com" target="blank"> Ladislas Nalborczyk </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes de cours - Introduction à la modélisation statistique bayésienne</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
Ce livret est en "<b>Open Review</b>". Votre retour est essentiel afin de l'améliorer, pour vous-même ainsi que pour les futurs étudiant•e•s. Vous pouvez annoter le texte en <span style="background-color: #3297FD; color: white">le sélectionnant avec le curseur</span> et en cliquant sur l'icône <i class="h-icon-annotate"></i> dans le menu qui s'affiche en pop-up. Vous pouvez également lire les annotations des autres utilisateurs du livret en cliquant sur <i class="h-icon-chevron-left"></i> dans le coin supérieur droit de cette page.
</div>
 
<div id="beta-binomial" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapitre 2</span> Modèle beta-binomial<a href="2-beta-binomial.html#beta-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Introduction au chapitre blah blah…</p>
<div id="coefficient-binomial" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Coefficient binomial<a href="2-beta-binomial.html#coefficient-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:fonction-factorielle" class="definition"><strong>Définition 2.1  (Fonction factorielle) </strong></span>On appelle fonction factorielle la fonction qui à tout entier naturel <span class="math inline">\(n\)</span> associe l’entier :</p>
<p><span class="math display">\[N! = N \times (N - 1) \times (N - 2) \times \cdots \times 3 \times 2 \times 1.\]</span></p>
</div>
<div class="definition">
<p><span id="def:coefficient-binomial" class="definition"><strong>Définition 2.2  (Coefficient binomial) </strong></span>For any nonnegative integers <span class="math inline">\(k\)</span> and <span class="math inline">\(n\)</span>, the binomial coefficient…</p>
</div>
<div class="theorem">
<p><span id="thm:coefficient-binomial-formule" class="theorem"><strong>Théorème 2.1  (Formule du coefficient binomial) </strong></span>For <span class="math inline">\(k \leq n\)</span>, we have:</p>
<p><span class="math display">\[
\left(\begin{array}{l}n \\ k\end{array}\right)=\frac{n(n-1) \cdots(n-k+1)}{k !}=\frac{n !}{(n-k) ! k !}
\]</span>
For <span class="math inline">\(k &gt; n\)</span>, we have <span class="math inline">\(\left(\begin{array}{l}n \\ k\end{array}\right) = 0\)</span>.</p>
</div>
<div class="note">
<p>
Blah blah blah…
</p>
</div>
</div>
<div id="le-modèle-beta-binomial" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Le modèle Beta-Binomial<a href="2-beta-binomial.html#le-modèle-beta-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Pourquoi ce modèle ?</p>
<p>Le modèle Beta-Binomial couvre un grand nombre de problèmes de la vie courante :</p>
<pre><code>- Réussite / échec à un test
- Présence / absence d&#39;effets secondaires lors du test d&#39;un médicament
- Résultat d&#39;un questionnaire à réponse binaire vrai / faux 
- Estimation des résultats du deuxième tour de l&#39;élection présidentielle </code></pre>
<p>C’est un modèle simple</p>
<pre><code>- Un seul paramètre
- Solution analytique</code></pre>
<div id="loi-de-bernoulli" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Loi de Bernoulli<a href="2-beta-binomial.html#loi-de-bernoulli" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>S’applique à toutes les situations où le processus de génération des données ne peut résulter qu’en deux issues mutuellement exclusives (e.g., un lancer de pièce). À chaque essai, si on admet que <span class="math inline">\(\Pr(\text{face}) = \theta\)</span>, alors <span class="math inline">\(\Pr(\text{pile}) = 1 - \theta\)</span>.</p>
<p>Depuis Bernoulli, on sait calculer la probabilité du résultat d’un lancer de pièce, du moment que l’on connait le biais de la pièce <span class="math inline">\(\theta\)</span>. Admettons que <span class="math inline">\(Y = 0\)</span> lorsqu’on obtient pile, et que <span class="math inline">\(Y = 1\)</span> lorsqu’on obtient face. Alors <span class="math inline">\(Y\)</span> est distribuée selon une loi de Bernoulli :</p>
<p><span class="math display">\[p(y) = \Pr(Y = y \ | \ \theta) = \theta^{y} (1 - \theta)^{(1 - y)}\]</span></p>
<p>En remplacant <span class="math inline">\(y\)</span> par <span class="math inline">\(0\)</span> ou <span class="math inline">\(1\)</span>, on retombe bien sur nos observations précédentes :</p>
<p><span class="math display">\[\Pr(Y = 0 \ | \ \theta) = \theta^{0} (1 - \theta)^{(1 - 0)} = 1 \times (1 - \theta) = 1 - \theta\]</span></p>
<p><span class="math display">\[\Pr(Y = 1 \ | \ \theta) = \theta^{1} (1 - \theta)^{(1 - 1)} = \theta \times 1 = \theta\]</span></p>
</div>
<div id="processus-de-bernoulli" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Processus de Bernoulli<a href="2-beta-binomial.html#processus-de-bernoulli" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si l’on dispose d’une suite de lancers <span class="math inline">\(\{Y_i\}\)</span> indépendants et identiquement distribués (i.e., chaque lancer a une distribution de Bernoulli de probabilité <span class="math inline">\(\theta\)</span>), l’ensemble de ces lancers peut être décrit par une <strong>distribution binomiale</strong>.</p>
<p>Par exemple, imaginons que l’on dispose de la séquence de cinq lancers suivants : Pile, Pile, Pile, Face, Face. On peut recoder cette séquence en <span class="math inline">\(\{0, 0, 0, 1, 1\}\)</span>.</p>
<p>Rappel : La probabilité de chaque <span class="math inline">\(1\)</span> est <span class="math inline">\(\theta\)</span> est la probabilité de chaque <span class="math inline">\(0\)</span> est <span class="math inline">\(1 - \theta\)</span>.</p>
<p>Quelle est la probabilité d’obtenir 2 faces sur 5 lancers ?</p>
</div>
<div id="processus-de-bernoulli-1" class="section level3 hasAnchor" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Processus de Bernoulli<a href="2-beta-binomial.html#processus-de-bernoulli-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sachant que les essais sont indépendants les uns des autres, la probabilité d’obtenir cette séquence est de <span class="math inline">\((1 - \theta) \times (1 - \theta) \times (1 - \theta) \times \theta \times \theta\)</span>, c’est à dire : <span class="math inline">\(\theta^{2} (1 - \theta)^{3}\)</span>.</p>
<p>On peut généraliser ce résultat pour une séquence de <span class="math inline">\(n\)</span> lancers et <span class="math inline">\(y\)</span> “succès” :</p>
<p><span class="math display">\[\theta^{y} (1 - \theta)^{n - y}\]</span></p>
<p>Mais, jusque là on a considéré seulement une seule séquence résultant en 2 succès pour 5 lancers, mais il existe de nombreuses séquences pouvant résulter en 2 succès pour 5 lancers (e.g., <span class="math inline">\(\{0, 0, 1, 0, 1\}\)</span>)…</p>
</div>
<div id="coefficient-binomial-1" class="section level3 hasAnchor" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Coefficient binomial<a href="2-beta-binomial.html#coefficient-binomial-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Le <strong>coefficient binomial</strong> nous permet de calculer le nombre d’arrangements possibles résultant en <span class="math inline">\(y\)</span> succès pour <span class="math inline">\(n\)</span> lancers de la manière suivante :</p>
<p><span class="math display">\[
\left(\begin{array}{l} n \\ y \end{array}\right) = C_{n}^{y} = \frac{n !}{y !(n - y) !}
\]</span></p>
<p>Par exemple pour <span class="math inline">\(y = 1\)</span> et <span class="math inline">\(n = 3\)</span>, on sait qu’il existe 3 arrangements possibles : <span class="math inline">\(\{0, 0, 1\}, \{0, 1, 0\}, \{1, 0, 0\}\)</span>. On peut vérifier ça par le calcul, en appliquant la formule ci-dessus.</p>
<p><span class="math display">\[
\left(\begin{array}{l} 3 \\ 1\end{array}\right) = C_{1}^{3} = \frac{3 !}{1 !(3 - 1) !} = \frac{6}{2} = 3
\]</span></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="2-beta-binomial.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># computing the total number of possible arrangements in R</span></span>
<span id="cb28-2"><a href="2-beta-binomial.html#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">choose</span>(<span class="at">n =</span> <span class="dv">3</span>, <span class="at">k =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
</div>
<div id="loi-binomiale" class="section level3 hasAnchor" number="2.2.5">
<h3><span class="header-section-number">2.2.5</span> Loi binomiale<a href="2-beta-binomial.html#loi-binomiale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[
p(y \ | \ \theta) = \Pr(Y = y \ | \ \theta) = \left(\begin{array}{l} n \\ y \end{array}\right) \theta^{y}(1 - \theta)^{n - y}
\]</span></p>
<p>La loi binomiale nous permet de calculer la probabilité d’obtenir <span class="math inline">\(y\)</span> succès sur <span class="math inline">\(n\)</span> essais, pour un <span class="math inline">\(\theta\)</span> donné. Exemple de la distribution binomiale pour une pièce non biaisée (<span class="math inline">\(\theta = 0.5\)</span>), indiquant la probabilité d’obtenir <span class="math inline">\(n\)</span> faces sur 10 lancers (en R: <code>dbinom(x = 0:10, size = 10, prob = 0.5)</code>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:binomial-barplot2"></span>
<img src="IMSB_files/figure-html/binomial-barplot2-1.svg" alt="Binomial distribution barplot..." width="75%" />
<p class="caption">
Figure 2.1: Binomial distribution barplot…
</p>
</div>
</div>
<div id="générer-des-données-à-partir-dune-distribution-binomiale" class="section level3 hasAnchor" number="2.2.6">
<h3><span class="header-section-number">2.2.6</span> Générer des données à partir d’une distribution binomiale<a href="2-beta-binomial.html#générer-des-données-à-partir-dune-distribution-binomiale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="2-beta-binomial.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb30-2"><a href="2-beta-binomial.html#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">666</span>) <span class="co"># for reproducibility</span></span>
<span id="cb30-3"><a href="2-beta-binomial.html#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="2-beta-binomial.html#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">500</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> <span class="fl">0.6</span>) <span class="sc">%&gt;%</span> <span class="co"># theta = 0.6</span></span>
<span id="cb30-5"><a href="2-beta-binomial.html#cb30-5" aria-hidden="true" tabindex="-1"></a>        data.frame <span class="sc">%&gt;%</span></span>
<span id="cb30-6"><a href="2-beta-binomial.html#cb30-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">x =</span> <span class="fu">seq_along</span>(.), <span class="at">y =</span> <span class="fu">cumsum</span>(.) <span class="sc">/</span> <span class="fu">seq_along</span>(.) ) <span class="sc">%&gt;%</span></span>
<span id="cb30-7"><a href="2-beta-binomial.html#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">log =</span> <span class="st">&quot;y&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-8"><a href="2-beta-binomial.html#cb30-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_line</span>(<span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb30-9"><a href="2-beta-binomial.html#cb30-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.5</span>, <span class="at">lty =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb30-10"><a href="2-beta-binomial.html#cb30-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">xlab</span>(<span class="st">&quot;Nombre de lancers&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-11"><a href="2-beta-binomial.html#cb30-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">ylab</span>(<span class="st">&quot;Proportion de faces&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-12"><a href="2-beta-binomial.html#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb30-13"><a href="2-beta-binomial.html#cb30-13" aria-hidden="true" tabindex="-1"></a>        <span class="fu">theme_bw</span>(<span class="at">base_size =</span> <span class="dv">18</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:berndata"></span>
<img src="IMSB_files/figure-html/berndata-1.svg" alt="Long-run..." width="75%" />
<p class="caption">
Figure 2.2: Long-run…
</p>
</div>
</div>
<div id="définition-du-modèle-likelihood" class="section level3 hasAnchor" number="2.2.7">
<h3><span class="header-section-number">2.2.7</span> Définition du modèle (likelihood)<a href="2-beta-binomial.html#définition-du-modèle-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="fonction-de-vraisemblance-likelihood" class="section level4 hasAnchor" number="2.2.7.1">
<h4><span class="header-section-number">2.2.7.1</span> Fonction de vraisemblance (likelihood)<a href="2-beta-binomial.html#fonction-de-vraisemblance-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Nous considérons <span class="math inline">\(y\)</span> comme étant le nombre de succès</li>
<li>Nous considérons le nombre d’observations <span class="math inline">\(n\)</span> comme étant une <strong>constante</strong></li>
<li>Nous considérons <span class="math inline">\(\theta\)</span> comme étant le <strong>paramètre</strong> de notre modèle (i.e., la probabilité de succès)</li>
</ul>
<p>La fonction de vraisemblance s’écrit de la manière suivante :</p>
<p><span class="math display">\[
\color{orangered}{\mathcal{L}(\theta\ |\ y, n) = p(y \ |\ \theta, n) = \left(\begin{array}{l} n \\ y \end{array}\right) \theta^{y}(1 - \theta)^{n - y} \propto \theta^{y}(1 - \theta)^{n - y}}
\]</span></p>
</div>
</div>
<div id="vraisemblance-versus-probabilité" class="section level3 hasAnchor" number="2.2.8">
<h3><span class="header-section-number">2.2.8</span> Vraisemblance versus probabilité<a href="2-beta-binomial.html#vraisemblance-versus-probabilité" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On lance à nouveau une pièce de biais <span class="math inline">\(\theta\)</span> (où <span class="math inline">\(\theta\)</span> représente la probabilité d’obtenir Face). On lance cette pièce deux fois et on obtient une Face et un Pile.</p>
<p>On peut calculer la probabilité de ces données selon (i.e., <em>en fonction de</em>) différentes valeurs de <span class="math inline">\(\theta\)</span> de la manière suivante :</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(F, P \ | \ \theta) + \Pr(P, F \ | \ \theta) &amp;= \theta(1 - \theta) + \theta(1 - \theta) \\
&amp;= 2 \times \Pr(P \ | \ \theta) \times \Pr(F \ | \ \theta) \\
&amp;= 2 \theta(1 - \theta)
\end{aligned}
\]</span></p>
<p>Cette probabilité est définie pour un jeu de données fixe et une valeur de <span class="math inline">\(\theta\)</span> variable. On peut représenter cette fonction visuellement. Représentation graphique de la fonction de vraisemblance de theta pour x = 1 et n = 2…</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="2-beta-binomial.html#cb31-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># number of heads</span></span>
<span id="cb31-2"><a href="2-beta-binomial.html#cb31-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="co"># number of trials</span></span>
<span id="cb31-3"><a href="2-beta-binomial.html#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="2-beta-binomial.html#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">theta =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="fl">1e3</span>) ) <span class="sc">%&gt;%</span></span>
<span id="cb31-5"><a href="2-beta-binomial.html#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">likelihood =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> y, <span class="at">size =</span> n, <span class="at">prob =</span> theta) ) <span class="sc">%&gt;%</span></span>
<span id="cb31-6"><a href="2-beta-binomial.html#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta, <span class="at">y =</span> likelihood) ) <span class="sc">+</span></span>
<span id="cb31-7"><a href="2-beta-binomial.html#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">color =</span> <span class="st">&quot;orangered&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;orangered&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb31-8"><a href="2-beta-binomial.html#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(theta, <span class="st">&quot; - Pr(face)&quot;</span>) ) ) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Likelihod&quot;</span>) <span class="sc">+</span></span>
<span id="cb31-9"><a href="2-beta-binomial.html#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>(<span class="at">base_size =</span> <span class="dv">20</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:likelihood"></span>
<img src="IMSB_files/figure-html/likelihood-1.svg" alt="Likelihood plot..." width="75%" />
<p class="caption">
Figure 2.3: Likelihood plot…
</p>
</div>
<p>Si on calcule l’aire sous la courbe de cette fonction, on obtient :</p>
<p><span class="math display">\[\int_{0}^{1} 2 \theta(1 - \theta) \mathrm{d} \theta = \frac{1}{3}\]</span></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="2-beta-binomial.html#cb32-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {<span class="dv">2</span> <span class="sc">*</span> theta <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta) }</span>
<span id="cb32-2"><a href="2-beta-binomial.html#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="at">f =</span> f, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 0.3333333 with absolute error &lt; 3.7e-15</code></pre>
<p>Quand on varie <span class="math inline">\(\theta\)</span>, la fonction de vraisemblance <em>n’est pas</em> une distribution de probabilité valide (i.e., son intégrale n’est pas égale à 1). On utilise le terme de <strong>vraisemblance</strong>, pour distinguer ce type de fonction des fonctions de densité de probabilité. On utilise la notation suivante pour mettre l’accent sur le fait que la fonction de vraisemblance est une fonction de <span class="math inline">\(\theta\)</span>, et que les données sont fixes : <span class="math inline">\(\mathcal{L}(\theta \ | \ data) = p(data \ | \ \theta)\)</span>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:likelihood-table">Tableau 2.1: </span>Vraisemblance versus probabilité pour deux lancers de pièce
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Nombre de Faces (y)
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;">
theta
</th>
<th style="text-align:center;">
0
</th>
<th style="text-align:center;">
1
</th>
<th style="text-align:center;">
2
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1.00
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
0.2
</td>
<td style="text-align:center;">
0.64
</td>
<td style="text-align:center;">
0.32
</td>
<td style="text-align:center;">
0.04
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
0.4
</td>
<td style="text-align:center;">
0.36
</td>
<td style="text-align:center;">
0.48
</td>
<td style="text-align:center;">
0.16
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
0.6
</td>
<td style="text-align:center;">
0.16
</td>
<td style="text-align:center;">
0.48
</td>
<td style="text-align:center;">
0.36
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
0.8
</td>
<td style="text-align:center;">
0.04
</td>
<td style="text-align:center;">
0.32
</td>
<td style="text-align:center;">
0.64
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
1.00
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
2.20
</td>
<td style="text-align:center;">
1.60
</td>
<td style="text-align:center;">
2.20
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>Notons que la vraisemblance de <span class="math inline">\(\theta\)</span> pour une donnée particulière est égale à la probabilité de cette donnée pour cette valeur de <span class="math inline">\(\theta\)</span>. Cependant, la <em>distribution</em> de ces vraisemblances (en colonne) n’est pas une distribution de probabilités. Dans l’analyse bayésienne, <strong>les données sont considérées comme fixes</strong> et la valeur de <span class="math inline">\(\theta\)</span> est considérée comme une <strong>variable aléatoire</strong>.</p>
</div>
<div id="définition-du-prior" class="section level3 hasAnchor" number="2.2.9">
<h3><span class="header-section-number">2.2.9</span> Définition du prior<a href="2-beta-binomial.html#définition-du-prior" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Comment définir un prior dans le cas du lancer de pièce ?</p>
<p><strong>Aspect sémantique</strong> <span class="math inline">\(~\rightarrow~\)</span> <em>doit pouvoir rendre compte</em> :
+ D’une absence d’information
+ D’une connaissance d’observations antérieures concernant la pièce étudiée
+ D’un niveau d’incertitude concernant ces observations antérieures</p>
<p><strong>Aspect mathématique</strong> <span class="math inline">\(~\rightarrow~\)</span> <em>pour une solution entièrement analytique</em> :
+ Les distributions a priori et a posteriori doivent avoir la même forme
+ La vraisemblance marginale doit pouvoir se calculer analytiquement</p>
</div>
<div id="la-distribution-beta" class="section level3 hasAnchor" number="2.2.10">
<h3><span class="header-section-number">2.2.10</span> La distribution Beta<a href="2-beta-binomial.html#la-distribution-beta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[
\begin{aligned}
\color{steelblue}{p(\theta\ | \ a, b)} \ &amp;\color{steelblue}{= \mathrm{Beta}(\theta\ |\ a, b)} \\
&amp; \color{steelblue}{= \theta^{a - 1}(1 - \theta)^{b - 1} / B(a, b)} \\
&amp; \color{steelblue}{\propto \theta^{a - 1}(1 - \theta)^{b - 1}}
\end{aligned}
\]</span></p>
<p>où <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> sont deux paramètres tels que <span class="math inline">\(a \geq 0\)</span>, <span class="math inline">\(b \geq 0\)</span>, et <span class="math inline">\(B(a, b)\)</span> est une constante de normalisation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:beta1"></span>
<img src="IMSB_files/figure-html/beta1-1.svg" alt="Distribution Beta..." width="75%" />
<p class="caption">
Figure 2.4: Distribution Beta…
</p>
</div>
</div>
<div id="interprétation-des-paramètres-du-prior-beta" class="section level3 hasAnchor" number="2.2.11">
<h3><span class="header-section-number">2.2.11</span> Interprétation des paramètres du prior Beta<a href="2-beta-binomial.html#interprétation-des-paramètres-du-prior-beta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>On peut exprimer l’absence de connaissance a priori par <span class="math inline">\(a = b = 1\)</span> (distribution orange)</li>
<li>On peut exprimer un prior en faveur d’une absence de biais par <span class="math inline">\(a = b &gt; 2\)</span> (distribution verte)</li>
<li>On peut exprimer un biais en faveur de <em>Face</em> par <span class="math inline">\(a &gt; b\)</span> (distribution bleue)</li>
<li>On peut exprimer un biais en faveur de <em>Pile</em> par <span class="math inline">\(a &lt; b\)</span> (distribution violette)</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:beta2"></span>
<img src="IMSB_files/figure-html/beta2-1.svg" alt="Inteprétation des paramètres d'une distribution Beta." width="75%" />
<p class="caption">
Figure 2.5: Inteprétation des paramètres d’une distribution Beta.
</p>
</div>
<p>Le niveau de certitude augmente avec la somme <span class="math inline">\(\kappa = a + b\)</span></p>
<ul>
<li>Aucune idée sur la provenance de la pièce : <span class="math inline">\(a = b = 1\)</span> -&gt; <strong>prior plat</strong></li>
<li>En attendant le début de l’expérience, on a lancé la pièce 10 fois et observé 5 “Face” : <span class="math inline">\(a = b = 5\)</span> -&gt; <strong>prior peu informatif</strong></li>
<li>La pièce provient de la banque de France : <span class="math inline">\(a = b = 50\)</span> -&gt; <strong>prior fort</strong></li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:beta3"></span>
<img src="IMSB_files/figure-html/beta3-1.svg" alt="Interprétation des paramètres d'une distribution Beta..." width="75%" />
<p class="caption">
Figure 2.6: Interprétation des paramètres d’une distribution Beta…
</p>
</div>
<p>Supposons que l’on dispose d’une estimation de la valeur la plus probable <span class="math inline">\(\omega\)</span> du paramètre <span class="math inline">\(\theta\)</span>. On peut reparamétriser la distribution Beta en fonction du mode <span class="math inline">\(\omega\)</span> et du niveau de certitude <span class="math inline">\(\kappa\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
a &amp;= \omega(\kappa - 2) + 1 \\
b &amp;= (1 - \omega)(\kappa - 2) + 1 &amp;&amp;\mbox{pour } \kappa &gt; 2
\end{aligned}
\]</span></p>
<p>Si <span class="math inline">\(\omega = 0.65\)</span> et <span class="math inline">\(\kappa = 25\)</span> alors <span class="math inline">\(p(\theta) = \mathrm{Beta}(\theta \ | \ 15.95, 9.05)\)</span>. <br>
Si <span class="math inline">\(\omega = 0.65\)</span> et <span class="math inline">\(\kappa = 10\)</span> alors <span class="math inline">\(p(\theta) = \mathrm{Beta}(\theta \ | \ 6.2, 3.8)\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:beta4"></span>
<img src="IMSB_files/figure-html/beta4-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.7: Blah blah…
</p>
</div>
</div>
<div id="prior-conjugué" class="section level3 hasAnchor" number="2.2.12">
<h3><span class="header-section-number">2.2.12</span> Prior conjugué<a href="2-beta-binomial.html#prior-conjugué" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Formellement, si <span class="math inline">\(\mathcal{F}\)</span> est une classe de distributions d’échantillonnage <span class="math inline">\(p(y|\theta)\)</span>, et <span class="math inline">\(\mathcal{P}\)</span> est une classe de distributions a priori pour <span class="math inline">\(\theta\)</span>, alors <span class="math inline">\(\mathcal{P}\)</span> est <strong>conjuguée</strong> à <span class="math inline">\(\mathcal{F}\)</span> si et seulement si :</p>
<p><span class="math display">\[
p(\theta|y) \in \mathcal{P} \text{ for all } p(\cdot | \theta) \in \mathcal{F} \text{ and } p(\cdot) \in \mathcal{P}
\]</span></p>
<p>(Gelman et al., 2013, p.35). En d’autres termes, un prior est appelé <strong>conjugué</strong> si, lorsqu’il est converti en une distribution a posteriori en étant multiplié par la vraisemblance, il conserve la même forme. Dans notre cas, le prior Beta est un prior conjugué pour la vraisemblance binomiale, car le posterior est également une distribution Beta.</p>
<blockquote>
<p>Le résultat du produit d’un prior Beta et d’une fonction de vraisemblance Binomiale est proportionnel à une distribution Beta. On dit alors que la distribution Beta est <strong>un prior conjugué</strong> de la fonction de vraisemblance Binomiale.</p>
</blockquote>
</div>
<div id="dérivation-analytique-de-la-distribution-a-posteriori" class="section level3 hasAnchor" number="2.2.13">
<h3><span class="header-section-number">2.2.13</span> Dérivation analytique de la distribution a posteriori<a href="2-beta-binomial.html#dérivation-analytique-de-la-distribution-a-posteriori" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Soit un prior défini par : <span class="math inline">\(\ \color{steelblue}{p(\theta \ | \ a, b) = \mathrm{Beta}(a, b) \propto \theta^{a - 1}(1 - \theta)^{b - 1}}\)</span></p>
<p>Soit une fonction de vraisemblance associée à <span class="math inline">\(y\)</span> “Face” pour <span class="math inline">\(n\)</span> lancers : <span class="math inline">\(\ \color{orangered}{p(y \ | \ n, \theta) = \mathrm{Bin}(y \ | \ n, \theta) = \left(\begin{array}{l} n \\ y \end{array}\right) \theta^{y}(1 - \theta)^{n - y} \propto \theta^{y}(1 - \theta)^{n - y}}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\color{purple}{p(\theta \ | \ y, n)} &amp;\propto \color{orangered}{p(y \ | \ n, \theta)} \ \color{steelblue}{p(\theta)} &amp;&amp;\mbox{Théorème de Bayes} \\
&amp;\propto \color{orangered}{\mathrm{Bin}(y \ | \ n, \theta)} \ \color{steelblue}{\mathrm{Beta}(\theta \ | \ a, b)} \\
&amp;\propto \color{orangered}{\theta^{y}(1 - \theta)^{n - y}} \ \color{steelblue}{\theta^{a - 1}(1 - \theta)^{b - 1}} &amp;&amp;\mbox{Application des formules précédentes} \\
&amp;\propto \color{purple}{\theta}^{\color{orangered}{y} + \color{steelblue}{a - 1}}\color{purple}{(1 - \theta)}^{\color{orangered}{n - y} + \color{steelblue}{b - 1}} &amp;&amp;\mbox{En regroupant les termes identiques} \\
&amp;\propto \color{purple}{\theta^{a&#39; - 1}(1 - \theta)^{b&#39; - 1}} &amp;&amp;\mbox{Avec } a&#39; = y + a \mbox{ et } b&#39; = n - y + b \\
\color{purple}{p(\theta \ | \ y, n)} \ &amp;= \color{purple}{\mathrm{Beta}(y + a, n - y + b)}
\end{aligned}
\]</span></p>
</div>
<div id="un-exemple-pour-digérer" class="section level3 hasAnchor" number="2.2.14">
<h3><span class="header-section-number">2.2.14</span> Un exemple pour digérer<a href="2-beta-binomial.html#un-exemple-pour-digérer" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On observe <span class="math inline">\(y = 7\)</span> réponses correctes sur <span class="math inline">\(n = 10\)</span> questions. On choisit un prior <span class="math inline">\(\mathrm{Beta}(1, 1)\)</span>, c’est à dire un prior uniforme sur <span class="math inline">\([0, 1]\)</span>. Ce prior équivaut à une connaissance a priori de 0 succès et 0 échecs (i.e., prior plat).</p>
<p>La distribution postérieure est donnée par :</p>
<p><span class="math display">\[
\begin{aligned}
\color{purple}{p(\theta \ | \ y, n)} &amp;\propto \color{orangered}{p(y \ | \ n, \theta)} \ \color{steelblue}{p(\theta)} \\
&amp;\propto \color{orangered}{\mathrm{Bin}(7 \ | \ 10, \theta)} \ \color{steelblue}{\mathrm{Beta}(\theta \ | \ 1, 1)} \\
&amp;= \color{purple}{\mathrm{Beta}(y + a, n - y + b)} \\
&amp;= \color{purple}{\mathrm{Beta}(8, 4)}
\end{aligned}
\]</span></p>
<p>La moyenne de la distribution postérieure est donnée par :</p>
<p><span class="math display">\[
\color{purple}{\underbrace{\frac{y + a}{n + a + b}}_{posterior}} = \color{orangered}{\underbrace{\frac{y}{n}}_{data}} \underbrace{\frac{n}{n + a + b}}_{weight} + \color{steelblue}{\underbrace{\frac{a}{a + b}}_{prior}} \underbrace{\frac{a + b}{n + a + b}}_{weight}
\]</span></p>
<p>Blah blah…</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:beta-exemple"></span>
<img src="IMSB_files/figure-html/beta-exemple-1.svg" alt="Exemple..." width="75%" />
<p class="caption">
Figure 2.8: Exemple…
</p>
</div>
</div>
<div id="influence-du-prior-sur-la-distribution-postérieure" class="section level3 hasAnchor" number="2.2.15">
<h3><span class="header-section-number">2.2.15</span> Influence du prior sur la distribution postérieure<a href="2-beta-binomial.html#influence-du-prior-sur-la-distribution-postérieure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cas <span class="math inline">\(n &lt; a + b, (n = 10, a = 4, b = 16)\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:posterior-exemple1"></span>
<img src="IMSB_files/figure-html/posterior-exemple1-1.svg" alt="Influence du prior..." width="75%" />
<p class="caption">
Figure 2.9: Influence du prior…
</p>
</div>
<p>Cas <span class="math inline">\(n = a + b, (n = 20, a = 4, b = 16)\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:posterior-exemple2"></span>
<img src="IMSB_files/figure-html/posterior-exemple2-1.svg" alt="Influence du prior..." width="75%" />
<p class="caption">
Figure 2.10: Influence du prior…
</p>
</div>
<p>Cas <span class="math inline">\(n &gt; a + b, (n = 40, a = 4, b = 16)\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:posterior-exemple3"></span>
<img src="IMSB_files/figure-html/posterior-exemple3-1.svg" alt="Influence du prior..." width="75%" />
<p class="caption">
Figure 2.11: Influence du prior…
</p>
</div>
</div>
<div id="ce-quil-faut-retenir" class="section level3 hasAnchor" number="2.2.16">
<h3><span class="header-section-number">2.2.16</span> Ce qu’il faut retenir<a href="2-beta-binomial.html#ce-quil-faut-retenir" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>The posterior distribution is always a compromise between the prior distribution and the likelihood function. <br>
<em>Kruschke (2015)</em></p>
</blockquote>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:posterior-exemple4"></span>
<img src="IMSB_files/figure-html/posterior-exemple4-1.svg" alt="Influence du prior..." width="75%" />
<p class="caption">
Figure 2.12: Influence du prior…
</p>
</div>
<p>Plus on a de données, moins le prior a d’influence dans l’estimation de la distribution a posteriori (et réciproquement).</p>
<p>Attention : Lorsque le prior accorde une probabilité de 0 à certaines valeurs de <span class="math inline">\(\theta\)</span>, le modèle est incapable d’apprendre (ces valeurs sont alors considérées comme “impossibles”)…</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:posterior-exemple5"></span>
<img src="IMSB_files/figure-html/posterior-exemple5-1.svg" alt="Influence du prior..." width="75%" />
<p class="caption">
Figure 2.13: Influence du prior…
</p>
</div>
</div>
<div id="la-vraisemblance-marginale-the-devil-is-in-the-denominator" class="section level3 hasAnchor" number="2.2.17">
<h3><span class="header-section-number">2.2.17</span> La vraisemblance marginale (the devil is in the denominator)<a href="2-beta-binomial.html#la-vraisemblance-marginale-the-devil-is-in-the-denominator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[
Posterior = \frac{Likelihood \ \times \ Prior}{Marginal \ Likelihood} \propto Likelihood \ \times \ Prior
\]</span></p>
<p><span class="math display">\[
p(\theta \ | \ data) = \frac{p(data \ | \ \theta) \ \times \ p(\theta)}{p(data)} \propto p(data \ | \ \theta) \ \times \ p(\theta)
\]</span></p>
<p>Si on zoom sur la vraisemblance marginale (aussi connue comme <em>evidence</em>)…</p>
<p><span class="math display">\[
\begin{aligned}
\color{green}{p(data)} &amp;= \int p(data,\theta) \, \mathrm d\theta &amp;&amp;\text{Marginalisation sur le paramètre } \theta \\
\color{green}{p(data)} &amp;= \color{green}{\int p(data \ | \ \theta) \ p(\theta) \, \mathrm{d} \theta} &amp;&amp; \text{Application de la règle du produit}
\end{aligned}
\]</span></p>
<p>Petit problème : <span class="math inline">\(p(data)\)</span> se calcule en calculant la somme (pour des variables discrètes) ou l’intégrale (pour des variables continues) de la densité conjointe <span class="math inline">\(p(data, \theta)\)</span> sur toutes les valeurs possibles de <span class="math inline">\(\theta\)</span>. Cela se complique lorsque le modèle comprend plusieurs paramètres.</p>
<p>Par exemple pour deux paramètres discrets :</p>
<p><span class="math display">\[
p(data) = \sum_{\theta_{1}} \sum_{\theta_{2}} p(data, \theta_{1}, \theta_{2})
\]</span></p>
<p>Et pour un modèle avec deux paramètres continus :</p>
<p><span class="math display">\[
p(data) = \int\limits_{\theta_{1}} \int\limits_{\theta_{2}} p(data, \theta_{1}, \theta_{2}) \mathrm{d} \theta_{1} \mathrm{d} \theta_{2}
\]</span></p>
<p>Trois méthodes pour résoudre (contourner) ce problème :</p>
<ol style="list-style-type: decimal">
<li><p>Solution analytique <span class="math inline">\(~\longrightarrow~\)</span> Utilisation d’un prior conjugué (e.g., le modèle Beta-Binomial)</p></li>
<li><p>Solution discrètisée <span class="math inline">\(~\longrightarrow~\)</span> Calcul de la solution sur un ensemble fini de points (grid method)</p></li>
<li><p>Solution approchée <span class="math inline">\(~\longrightarrow~\)</span> On échantillonne “intelligemment” l’espace conjoint des paramètres (méthodes MCMC, cf. cours n°05)</p></li>
</ol>
</div>
<div id="la-distribution-postérieure-solution-analytique" class="section level3 hasAnchor" number="2.2.18">
<h3><span class="header-section-number">2.2.18</span> La distribution postérieure, solution analytique<a href="2-beta-binomial.html#la-distribution-postérieure-solution-analytique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="distributions-discrètes" class="section level4 hasAnchor" number="2.2.18.1">
<h4><span class="header-section-number">2.2.18.1</span> Distributions discrètes<a href="2-beta-binomial.html#distributions-discrètes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:discrete"></span>
<img src="figures/discrete.png" alt="Illustration of the Mersenne-Twister algorithm... Figure from..." width="100%" />
<p class="caption">
Figure 2.14: Illustration of the Mersenne-Twister algorithm… Figure from…
</p>
</div>
</div>
<div id="distributions-continues" class="section level4 hasAnchor" number="2.2.18.2">
<h4><span class="header-section-number">2.2.18.2</span> Distributions continues<a href="2-beta-binomial.html#distributions-continues" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:continuous"></span>
<img src="figures/continuous.png" alt="Illustration of the Mersenne-Twister algorithm... Figure from..." width="100%" />
<p class="caption">
Figure 2.15: Illustration of the Mersenne-Twister algorithm… Figure from…
</p>
</div>
<p>Problème : Cette solution est très contraignante. Idéalement, le modèle (likelihood + prior) devrait être défini à partir de l’interprétation que l’on peut faire des paramètres de ces distributions, et non pour faciliter les calculs…</p>
</div>
</div>
<div id="la-distribution-postérieure-grid-method" class="section level3 hasAnchor" number="2.2.19">
<h3><span class="header-section-number">2.2.19</span> La distribution postérieure, grid method<a href="2-beta-binomial.html#la-distribution-postérieure-grid-method" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Définir la grille</strong></li>
<li>Calculer la valeur du prior pour chaque valeur de la grille</li>
<li>Calculer la valeur de la vraisemblance pour chaque valeur de la grille</li>
<li>Calculer le produit prior x vraisemblance pour chaque valeur de la grille, puis normalisation du résultat</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grid1"></span>
<img src="IMSB_files/figure-html/grid1-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.16: Blah blah…
</p>
</div>
<ol style="list-style-type: decimal">
<li>Définir la grille</li>
<li><strong>Calculer la valeur du prior pour chaque valeur de la grille</strong></li>
<li>Calculer la valeur de la vraisemblance pour chaque valeur de la grille</li>
<li>Calculer le produit prior x vraisemblance pour chaque valeur de la grille, puis normalisation du résultat</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grid2"></span>
<img src="IMSB_files/figure-html/grid2-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.17: Blah blah…
</p>
</div>
<ol style="list-style-type: decimal">
<li>Définir la grille</li>
<li>Calculer la valeur du prior pour chaque valeur de la grille</li>
<li><strong>Calculer la valeur de la vraisemblance pour chaque valeur de la grille</strong></li>
<li>Calculer le produit prior x vraisemblance pour chaque valeur de la grille, puis normalisation du résultat</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grid3"></span>
<img src="IMSB_files/figure-html/grid3-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.18: Blah blah…
</p>
</div>
<ol style="list-style-type: decimal">
<li>Définir la grille</li>
<li>Calculer la valeur du prior pour chaque valeur de la grille</li>
<li>Calculer la valeur de la vraisemblance pour chaque valeur de la grille</li>
<li><strong>Calculer le produit prior x vraisemblance pour chaque valeur de la grille, puis normalisation du résultat</strong></li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grid4"></span>
<img src="IMSB_files/figure-html/grid4-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.19: Blah blah…
</p>
</div>
<ol style="list-style-type: decimal">
<li>Définir la grille</li>
<li>Calculer la valeur du prior pour chaque valeur de la grille</li>
<li>Calculer la valeur de la vraisemblance pour chaque valeur de la grille</li>
<li><strong>Calculer le produit prior x vraisemblance pour chaque valeur de la grille, puis normalisation du résultat</strong></li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grid5"></span>
<img src="IMSB_files/figure-html/grid5-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.20: Blah blah…
</p>
</div>
<p>Problème du nombre de paramètres… En affinant la grille on augmente le temps de calcul :</p>
<ul>
<li>3 paramètres avec une grille de <span class="math inline">\(10^3\)</span> noeuds = une grille de <span class="math inline">\(10^9\)</span> points de calcul</li>
<li>10 paramètres avec une grille de <span class="math inline">\(10^3\)</span> noeuds = une grille de <span class="math inline">\(10^{30}\)</span> points de calcul</li>
</ul>
<p>Le “superordinateur” chinois Tianhe-2 réalise <span class="math inline">\(33,8 \text{×} 10^{15}\)</span> opérations par seconde. Si on considère qu’il réalise 3 opérations par noeud de la grille, il lui faudrait <span class="math inline">\(10^{14}\)</span> secondes pour parcourir la grille une fois (pour comparaison, l’âge de l’univers est approximativement de <span class="math inline">\((4,354 ± 0,012)\text{×}10^{17}\)</span> secondes)…</p>
</div>
<div id="échantillonner-la-distribution-postérieure" class="section level3 hasAnchor" number="2.2.20">
<h3><span class="header-section-number">2.2.20</span> Échantillonner la distribution postérieure<a href="2-beta-binomial.html#échantillonner-la-distribution-postérieure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour échantillonner une distribution postérieure, on peut utiliser une approximation par grille ou différentes implémentations des méthodes MCMC (e.g., Metropolis-Hasting, Gibbs, Hamilton, cf. Cours n°05).</p>
<p>En pratique :</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="2-beta-binomial.html#cb34-1" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>) <span class="co"># creating a grid</span></span>
<span id="cb34-2"><a href="2-beta-binomial.html#cb34-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>) <span class="co"># uniform prior</span></span>
<span id="cb34-3"><a href="2-beta-binomial.html#cb34-3" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(y, <span class="at">size =</span> n, <span class="at">prob =</span> p_grid) <span class="co"># computes likelihood</span></span>
<span id="cb34-4"><a href="2-beta-binomial.html#cb34-4" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> (likelihood <span class="sc">*</span> prior) <span class="sc">/</span> <span class="fu">sum</span>(likelihood <span class="sc">*</span> prior) <span class="co"># computes posterior</span></span>
<span id="cb34-5"><a href="2-beta-binomial.html#cb34-5" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(posterior, <span class="at">size =</span> <span class="fl">1e3</span>, <span class="at">prob =</span> posterior, <span class="at">replace =</span> <span class="cn">TRUE</span>) <span class="co"># sampling</span></span>
<span id="cb34-6"><a href="2-beta-binomial.html#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(samples, <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">xlab =</span> <span class="fu">expression</span>(theta), <span class="at">cex.axis =</span> <span class="dv">1</span>, <span class="at">cex.lab =</span> <span class="fl">1.5</span>) <span class="co"># histogram</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling1"></span>
<img src="IMSB_files/figure-html/sampling1-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.21: Blah blah…
</p>
</div>
<p>La précision dépend de la taille de l’échantillon…</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling2"></span>
<img src="IMSB_files/figure-html/sampling2-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.22: Blah blah…
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling3"></span>
<img src="IMSB_files/figure-html/sampling3-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.23: Blah blah…
</p>
</div>
</div>
<div id="la-distribution-postérieure-résumé" class="section level3 hasAnchor" number="2.2.21">
<h3><span class="header-section-number">2.2.21</span> La distribution postérieure, résumé<a href="2-beta-binomial.html#la-distribution-postérieure-résumé" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Cas analytique :</li>
</ul>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="2-beta-binomial.html#cb35-1" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb35-2"><a href="2-beta-binomial.html#cb35-2" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> b <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># parameters of the Beta prior</span></span>
<span id="cb35-3"><a href="2-beta-binomial.html#cb35-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">9</span> <span class="co"># number of observations</span></span>
<span id="cb35-4"><a href="2-beta-binomial.html#cb35-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">6</span> <span class="co"># number of successes</span></span>
<span id="cb35-5"><a href="2-beta-binomial.html#cb35-5" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(p_grid, z <span class="sc">+</span> a <span class="sc">-</span> <span class="dv">1</span>, N <span class="sc">-</span> z <span class="sc">+</span> b <span class="sc">-</span> <span class="dv">1</span>)</span></code></pre></div>
<ul>
<li>Grid method :</li>
</ul>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="2-beta-binomial.html#cb36-1" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb36-2"><a href="2-beta-binomial.html#cb36-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>) <span class="co"># uniform prior</span></span>
<span id="cb36-3"><a href="2-beta-binomial.html#cb36-3" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(y, <span class="at">size =</span> n, <span class="at">prob =</span> p_grid)</span>
<span id="cb36-4"><a href="2-beta-binomial.html#cb36-4" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> (likelihood <span class="sc">*</span> prior) <span class="sc">/</span> <span class="fu">sum</span>(likelihood <span class="sc">*</span> prior)</span></code></pre></div>
<ul>
<li>Échantillonner la distribution postérieure :</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="2-beta-binomial.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(data, <span class="at">size =</span> trajLength, <span class="at">prob =</span> prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><strong>Méthode analytique</strong>
* La distribution postérieure est décrite explicitement
* Le modèle est fortement contraint</p>
<p><strong>Méthode Grid</strong>
* La distribution postérieure n’est donnée que pour un ensemble fini de valeurs
* Plus la grille est fine, meilleure est l’estimation de la distribution postérieure
* Compromis <em>Précision - Temps de calcul</em></p>
</div>
<div id="utiliser-les-échantillons-pour-résumer-la-distribution-postérieure" class="section level3 hasAnchor" number="2.2.22">
<h3><span class="header-section-number">2.2.22</span> Utiliser les échantillons pour résumer la distribution postérieure<a href="2-beta-binomial.html#utiliser-les-échantillons-pour-résumer-la-distribution-postérieure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="estimation-de-la-tendance-centrale" class="section level4 hasAnchor" number="2.2.22.1">
<h4><span class="header-section-number">2.2.22.1</span> Estimation de la tendance centrale<a href="2-beta-binomial.html#estimation-de-la-tendance-centrale" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>À partir d’un ensemble d’échantillons d’une distribution postérieure, on peut calculer la moyenne, le mode, et la médiane. Par exemple pour un prior uniforme, 10 lancers et 3 Faces.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="2-beta-binomial.html#cb38-1" aria-hidden="true" tabindex="-1"></a>mode_posterior <span class="ot">&lt;-</span> <span class="fu">find_mode</span>(samples) <span class="co"># in blue</span></span>
<span id="cb38-2"><a href="2-beta-binomial.html#cb38-2" aria-hidden="true" tabindex="-1"></a>mean_posterior <span class="ot">&lt;-</span> <span class="fu">mean</span>(samples) <span class="co"># in orange</span></span>
<span id="cb38-3"><a href="2-beta-binomial.html#cb38-3" aria-hidden="true" tabindex="-1"></a>median_posterior <span class="ot">&lt;-</span> <span class="fu">median</span>(samples) <span class="co"># in green</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tendance-centrale2"></span>
<img src="IMSB_files/figure-html/tendance-centrale2-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.24: Blah blah…
</p>
</div>
<p>Quelle est la probabilité que le biais de la pièce <span class="math inline">\(\theta\)</span> soit supérieur à 0.5 ?</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="2-beta-binomial.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&gt;</span> <span class="fl">0.5</span>) <span class="sc">/</span> <span class="fu">length</span>(samples) <span class="co"># length(samples) is the number of samples</span></span></code></pre></div>
<pre><code>## [1] 0.112</code></pre>
<p>Quelle est la probabilité que le biais de la pièce <span class="math inline">\(\theta\)</span> soit compris entre 0.2 et 0.4 ?</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="2-beta-binomial.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&gt;</span> <span class="fl">0.2</span> <span class="sc">&amp;</span> samples <span class="sc">&lt;</span> <span class="fl">0.4</span>) <span class="sc">/</span> <span class="fl">1e4</span> <span class="co"># length(samples) is the number of samples</span></span></code></pre></div>
<pre><code>## [1] 0.5482</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interval-prob-plot"></span>
<img src="IMSB_files/figure-html/interval-prob-plot-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.25: Blah blah…
</p>
</div>
</div>
</div>
<div id="highest-density-interval-hdi" class="section level3 hasAnchor" number="2.2.23">
<h3><span class="header-section-number">2.2.23</span> Highest density interval (HDI)<a href="2-beta-binomial.html#highest-density-interval-hdi" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Le HDI indique les valeurs du paramètre qui sont les plus probables (sachant les données et le prior)</li>
<li>Plus le HDI est étroit et plus le degré de certitude est élevé</li>
<li>La largeur du HDI diminue avec l’augmentation du nombre de mesures</li>
</ul>
<blockquote>
<p>Définition: les valeurs du paramètre <span class="math inline">\(\theta\)</span> contenues dans un HDI à 89% sont telles que <span class="math inline">\(p(\theta) &gt; W\)</span> où <span class="math inline">\(W\)</span> satisfait la condition suivante :</p>
<p><span class="math display">\[\int_{\theta \ : \ p(\theta) &gt; W} p(\theta) \, \mathrm{d} \theta = 0.89.\]</span></p>
</blockquote>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:hdi"></span>
<img src="figures/HDI.png" alt="Illustration of the Mersenne-Twister algorithm... Figure from..." width="100%" />
<p class="caption">
Figure 2.26: Illustration of the Mersenne-Twister algorithm… Figure from…
</p>
</div>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="2-beta-binomial.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(BEST)</span>
<span id="cb43-2"><a href="2-beta-binomial.html#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="2-beta-binomial.html#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">666</span>)</span>
<span id="cb43-4"><a href="2-beta-binomial.html#cb43-4" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="fl">1e3</span>)</span>
<span id="cb43-5"><a href="2-beta-binomial.html#cb43-5" aria-hidden="true" tabindex="-1"></a>pTheta <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(p_grid, <span class="dv">3</span>, <span class="dv">10</span>)</span>
<span id="cb43-6"><a href="2-beta-binomial.html#cb43-6" aria-hidden="true" tabindex="-1"></a>massVec <span class="ot">&lt;-</span> pTheta <span class="sc">/</span> <span class="fu">sum</span>(pTheta)</span>
<span id="cb43-7"><a href="2-beta-binomial.html#cb43-7" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> pTheta)</span>
<span id="cb43-8"><a href="2-beta-binomial.html#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="2-beta-binomial.html#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plotPost</span>(samples, <span class="at">credMass =</span> <span class="fl">0.89</span>, <span class="at">cex =</span> <span class="fl">1.5</span>, <span class="at">xlab =</span> <span class="fu">expression</span>(theta), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>) )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plotpost1"></span>
<img src="IMSB_files/figure-html/plotpost1-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.27: Blah blah…
</p>
</div>
</div>
<div id="region-of-practical-equivalence-rope" class="section level3 hasAnchor" number="2.2.24">
<h3><span class="header-section-number">2.2.24</span> Region of practical equivalence (ROPE)<a href="2-beta-binomial.html#region-of-practical-equivalence-rope" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On l’utilise pour tester une hypothèse :</p>
<ul>
<li>La valeur du paramètre (e.g., <span class="math inline">\(\theta = 0.5\)</span>) est rejetée si le HDI est entièrement hors de la ROPE</li>
<li>La valeur du paramètre (e.g., <span class="math inline">\(\theta = 0.5\)</span>) est acceptée si le HDI est entièrement dans la ROPE</li>
<li>Si le HDI et la ROPE se chevauchent on ne peut pas conclure…</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rope"></span>
<img src="IMSB_files/figure-html/rope-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.28: Blah blah…
</p>
</div>
</div>
<div id="model-checking" class="section level3 hasAnchor" number="2.2.25">
<h3><span class="header-section-number">2.2.25</span> Model checking<a href="2-beta-binomial.html#model-checking" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Les deux rôles de la fonction de vraisemblance :</p>
<ul>
<li>C’est une fonction de <span class="math inline">\(\theta\)</span> pour le calcul de la distribution postérieure : <span class="math inline">\(\mathcal{L}(\theta \ | \ y, n)\)</span></li>
<li>Lorsque <span class="math inline">\(\theta\)</span> est connu / fixé, c’est une distribution de probabilité : <span class="math inline">\(p(y \ |\ \theta, n) = \theta^y(1 - \theta)^{(n - y)}\)</span></li>
</ul>
<p>On peut utiliser cette distribution de probabilité pour générer des données… !</p>
<p>Par exemple : Générer 10000 valeurs à partir d’une loi binomiale basée sur 9 lancers et une probabilité de Face de 0.6 :</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="2-beta-binomial.html#cb44-1" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.6</span>)</span></code></pre></div>
<p>Deux sources d’incertitude dans ces prédictions :</p>
<ul>
<li>Incertitude liée au processus d’échantillonnage <br>
-&gt; Chaque valeur apparaît avec une probabilité <span class="math inline">\(\theta\)</span></li>
<li>Incertitude sur la valeur de <span class="math inline">\(\theta\)</span> elle-même <br>
-&gt; Pour chaque valeur de <span class="math inline">\(\theta\)</span> on peut calculer une distribution implicite</li>
</ul>
<p>Par exemple : Générer 10000 valeurs à partir d’une loi binomiale basé sur 9 lancers et une probabilité de Face décrite par la distribution postérieure de <span class="math inline">\(\theta\)</span> :</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="2-beta-binomial.html#cb45-1" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fu">rbeta</span>(<span class="fl">1e4</span>, <span class="dv">16</span>, <span class="dv">10</span>) )</span></code></pre></div>
</div>
<div id="posterior-predictive-checking" class="section level3 hasAnchor" number="2.2.26">
<h3><span class="header-section-number">2.2.26</span> Posterior predictive checking<a href="2-beta-binomial.html#posterior-predictive-checking" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ppc"></span>
<img src="IMSB_files/figure-html/ppc-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 2.29: Blah blah…
</p>
</div>
<p>Blah blah…</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ppc-rethinking"></span>
<img src="figures/ModelPredictions.jpg" alt="Illustration of the posterior predictive checking procedure. Figure from McElreath (2016)." width="100%" />
<p class="caption">
Figure 2.30: Illustration of the posterior predictive checking procedure. Figure from McElreath (2016).
</p>
</div>
</div>
</div>
<div id="conclusions" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Conclusions<a href="2-beta-binomial.html#conclusions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>…</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="1-introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3-linear-regression1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/lnalborczyk/IMSB2022/_notes/doc/tree/master/02-beta-binomial.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IMSB.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
